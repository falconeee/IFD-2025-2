{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPXmkt-iKCeA"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTHYLssWfNUu",
        "outputId": "46bb7f4e-522c-4898-b1bc-ecc7024b2b03"
      },
      "outputs": [],
      "source": [
        "!pip install vibdata==1.1.1 signalAI==0.0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGC5F4WuQ8Qs"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "6pod38v0RKKx",
        "outputId": "c37ec1db-237c-41f3-b7a1-1c31d3eb7326"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Basic imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# vibdata\n",
        "import vibdata.raw as raw_datasets\n",
        "from vibdata.deep.DeepDataset import DeepDataset, convertDataset\n",
        "from vibdata.deep.signal.transforms import (\n",
        "    Sequential,\n",
        "    SplitSampleRate,\n",
        "    FeatureExtractor,\n",
        "    FilterByValue,\n",
        "    Split\n",
        ")\n",
        "from vibdata.deep.signal.core import SignalSample\n",
        "\n",
        "# SignalAI\n",
        "from signalAI.experiments.features_1d import Features1DExperiment\n",
        "from signalAI.utils.group_dataset import GroupDataset\n",
        "from signalAI.utils.fold_idx_generator import (\n",
        "    FoldIdxGeneratorUnbiased,\n",
        "    FoldIdxGeneratorBiased,\n",
        ")\n",
        "\n",
        "class GroupCWRULoad(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        return sample[\"metainfo\"][\"load\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gw9EnsSs276"
      },
      "source": [
        "# Deep Learning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRt2UWNpaPbh"
      },
      "source": [
        "## Import CRWU dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cckVlJSzUqnN"
      },
      "outputs": [],
      "source": [
        "raw_root_dir = \"../data/raw_data/cwru\"\n",
        "raw_dataset = raw_datasets.CWRU_raw(raw_root_dir, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rDx-9rht7Un"
      },
      "source": [
        "## Time domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmIzuXr-aVBm"
      },
      "source": [
        "### Filter by 48k SampleRate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t09LPCnRtMbu",
        "outputId": "6aa32f9b-c9b5-4eb0-9507-1a6894c56c17"
      },
      "outputs": [],
      "source": [
        "transforms_time = Sequential(\n",
        "    [\n",
        "        SplitSampleRate()\n",
        "    ]\n",
        ")\n",
        "print(transforms_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeeJ_8J3tRno"
      },
      "outputs": [],
      "source": [
        "deep_root_dir_time = \"../data/deep_data/deep_learning\"\n",
        "deep_dataset_time = convertDataset(raw_dataset,filter=FilterByValue(on_field=\"sample_rate\", values=48000),transforms=transforms_time, dir_path=deep_root_dir_time, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gufU833iax3I"
      },
      "source": [
        "## Generate Unbiased Folds Single Round"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd86Qz_Qth8u",
        "outputId": "74a72abc-7c83-4872-e1f3-7e698abb2344"
      },
      "outputs": [],
      "source": [
        "folds_singleround_deep = FoldIdxGeneratorUnbiased(deep_dataset_time, GroupCWRULoad , dataset_name=\"CWRU48k_deep\").generate_folds()\n",
        "folds_singleround_deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Unbiased Folds MultiRound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GroupMultiRoundCWRULoad(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        sample_metainfo = sample[\"metainfo\"]\n",
        "        return sample_metainfo[\"label\"].astype(str) + \" \" + sample_metainfo[\"load\"].astype(int).astype(str)\n",
        "\n",
        "CLASS_DEF = {0: \"N\", 1: \"O\", 2: \"I\", 3: \"R\"}\n",
        "CONDITION_DEF = {\"0\": \"0\", \"1\": \"1\", \"2\": \"2\", \"3\": \"3\"}\n",
        "folds_multiround_deep = FoldIdxGeneratorUnbiased(deep_dataset,\n",
        "                                    GroupMultiRoundCWRULoad ,\n",
        "                                    dataset_name=\"CWRU48k_deep\",\n",
        "                                    multiround=True,\n",
        "                                    class_def=CLASS_DEF,\n",
        "                                    condition_def=CONDITION_DEF).generate_folds()\n",
        "folds_multiround_deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1DdMvqe7Qs"
      },
      "source": [
        "## DeepLearning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt4WUe1EkNUQ"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbq0v5_lgAAW"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/base.py\n",
        "from abc import ABC, abstractmethod\n",
        "import json\n",
        "from typing import Optional, Dict, Any\n",
        "from vibdata.raw.base import RawVibrationDataset\n",
        "from vibdata.deep.signal.transforms import Transform\n",
        "\n",
        "class Experiment(ABC):\n",
        "    \"\"\"Classe base abstrata para todos os experimentos de classificação de vibração.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset: Optional[RawVibrationDataset] = None,\n",
        "        data_transform: Optional[Transform] = None,\n",
        "        feature_selector = None,\n",
        "        model = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Inicializa o experimento.\n",
        "\n",
        "        Args:\n",
        "            name: Nome identificador do experimento\n",
        "            description: Descrição detalhada do experimento\n",
        "            dataset: Conjunto de dados de vibração\n",
        "            data_transform: Transformação a ser aplicada nos dados brutos\n",
        "            data_division_method: Método de divisão dos dados (e.g., 'kfold', 'holdout')\n",
        "            data_division_params: Parâmetros para o método de divisão\n",
        "            feature_selector: Seletor de features (para experimentos com extração)\n",
        "            model: Modelo de machine learning/deep learning\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.dataset = dataset\n",
        "        self.data_transform = data_transform\n",
        "        self.feature_selector = feature_selector\n",
        "        self.model = model\n",
        "\n",
        "        # Resultados serão armazenados aqui\n",
        "        self.results = {}\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepara os dados para o experimento.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self):\n",
        "        \"\"\"Executa o experimento completo.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def save_results(self, filepath: str):\n",
        "        \"\"\"Salva os resultados do experimento.\"\"\"\n",
        "        # Implementação básica - pode ser extendida\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(self.results, f)\n",
        "\n",
        "    def load_results(self, filepath: str):\n",
        "        \"\"\"Carrega resultados de um experimento anterior.\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            self.results = json.load(f)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Experiment: {self.name}\\nDescription: {self.description}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS8nDnOpe_Le"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/deep_torch.py\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Tuple, Union\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from signalAI.utils.metrics import calculate_metrics\n",
        "from signalAI.utils.experiment_result import ExperimentResults, FoldResults\n",
        "import copy\n",
        "\n",
        "class TorchVibrationDataset(Dataset):\n",
        "    \"\"\"Wrapper to convert dataset samples into Torch tensors.\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Função auxiliar KL\n",
        "def kl_divergence(rho, rho_hat):\n",
        "    rho_hat = torch.mean(rho_hat, dim=0)\n",
        "    rho = torch.tensor([rho] * len(rho_hat), device=rho_hat.device)\n",
        "    epsilon = 1e-7\n",
        "    term1 = rho * torch.log((rho + epsilon) / (rho_hat + epsilon))\n",
        "    term2 = (1 - rho) * torch.log((1 - rho + epsilon) / (1 - rho_hat + epsilon))\n",
        "    return torch.sum(term1 + term2)\n",
        "\n",
        "class DeepLearningExperiment(Experiment):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset,\n",
        "        data_fold_idxs: List[int],\n",
        "        model: nn.Module,\n",
        "        criterion: Optional[nn.Module] = None,\n",
        "        # Parâmetros adaptados para o autoencoder\n",
        "        reconstruction_criterion: Optional[nn.Module] = None,\n",
        "        recon_loss_weight: float = 1.0,\n",
        "        sparsity_target: Optional[float] = None,\n",
        "        sparsity_weight: float = 0.0,\n",
        "        pretrain_epochs: int = 0, # Épocas de treinamento do autoencoder\n",
        "        optimizer_class: Optional[torch.optim.Optimizer] = optim.Adam,\n",
        "        batch_size: int = 32,\n",
        "        lr: float = 1e-3,\n",
        "        num_epochs: int = 20, # Épocas de treino do classificador\n",
        "        val_split: float = 0.2,\n",
        "        output_dir: str = \"results_torch\",\n",
        "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(name, description, dataset, model=model, **kwargs)\n",
        "        self.data_fold_idxs = data_fold_idxs\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.pretrain_epochs = pretrain_epochs\n",
        "        self.val_split = val_split\n",
        "        self.device = device\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.lr = lr\n",
        "        self.criterion = criterion if criterion is not None else nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.reconstruction_criterion = reconstruction_criterion\n",
        "        self.recon_loss_weight = recon_loss_weight\n",
        "        self.sparsity_target = sparsity_target\n",
        "        self.sparsity_weight = sparsity_weight\n",
        "        \n",
        "        self.is_sae_task = self.sparsity_target is not None and self.sparsity_weight > 0.0\n",
        "        # Define tipo do AutoEncoder utilizado\n",
        "        self.is_autoencoder_task = reconstruction_criterion is not None or self.is_sae_task or \"AE1D\" in model.__class__.__name__\n",
        "\n",
        "        if self.is_sae_task and self.reconstruction_criterion is None:\n",
        "             print(\"Warning: SAE task detected but no reconstruction_criterion. Defaulting to MSELoss.\")\n",
        "             self.reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
        "            model = torch.nn.DataParallel(model) \n",
        "        \n",
        "        # Guarda encoder e decoder\n",
        "        self.original_model = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        self.n_outer_folds = len(np.unique(data_fold_idxs))\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        features, labels = [], []\n",
        "        for sample in self.dataset:\n",
        "            features.append(sample['signal'][0]) \n",
        "            labels.append(sample['metainfo']['label'])\n",
        "        self.X = np.array(features)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.y = self.label_encoder.fit_transform(labels)\n",
        "\n",
        "    def _train_one_fold(\n",
        "        self, X_train, y_train, X_test, y_test, fold_idx: int\n",
        "    ) -> FoldResults:\n",
        "        \n",
        "        train_dataset = TorchVibrationDataset(X_train, y_train)\n",
        "        test_dataset = TorchVibrationDataset(X_test, y_test)\n",
        "        val_size = int(self.val_split * len(train_dataset))\n",
        "        train_size = len(train_dataset) - val_size\n",
        "        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        model = copy.deepcopy(self.model.to(self.device))\n",
        "        model_core = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        # Verificação da estrutura de AE (encoder, decoder, classifier)\n",
        "        has_ae_structure = hasattr(model_core, 'encoder') and hasattr(model_core, 'decoder') and hasattr(model_core, 'classifier')\n",
        "\n",
        "        # Treinamento do AutoEncoder\n",
        "        if self.is_autoencoder_task and self.pretrain_epochs > 0 and has_ae_structure:\n",
        "            print(f\"[Fold {fold_idx}] AutoEncoder training ({self.pretrain_epochs} epochs)...\")\n",
        "            \n",
        "            # Otimizador Encoder + Decoder\n",
        "            optimizer_ae = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.decoder.parameters()}\n",
        "            ], lr=self.lr)\n",
        "\n",
        "            for epoch in range(self.pretrain_epochs):\n",
        "                model.train()\n",
        "                running_recon_loss = 0.0\n",
        "                \n",
        "                for xb, _ in train_loader:\n",
        "                    xb = xb.to(self.device)\n",
        "                    input_data = xb\n",
        "\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                        xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    optimizer_ae.zero_grad()\n",
        "                    outputs = model(xb) # (class, recon, [sparsity])\n",
        "\n",
        "                    if isinstance(outputs, tuple):\n",
        "                        # Foco na reconstrução\n",
        "                        reconstruction = outputs[1] \n",
        "                        \n",
        "                        loss = self.reconstruction_criterion(reconstruction, input_data)\n",
        "                        \n",
        "                        # Adiciona esparsidade se for SAE\n",
        "                        if self.is_sae_task and len(outputs) > 2:\n",
        "                            latent_features = outputs[2]\n",
        "                            loss += self.sparsity_weight * kl_divergence(self.sparsity_target, latent_features)\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer_ae.step()\n",
        "                        running_recon_loss += loss.item() * input_data.size(0)\n",
        "                \n",
        "                avg_recon_loss = running_recon_loss / len(train_loader.dataset)\n",
        "                if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                    print(f\"  [Pre-train] Epoch {epoch+1}/{self.pretrain_epochs} Recon Loss: {avg_recon_loss:.4f}\")\n",
        "\n",
        "        # Treino do classificador\n",
        "        print(f\"[Fold {fold_idx}] Classifier training ({self.num_epochs} epochs)...\")\n",
        "\n",
        "        # Define otimizador para a fase supervisionada\n",
        "        if has_ae_structure and self.is_autoencoder_task:\n",
        "            # Se for AE: Treina Encoder + Classifier (Decoder congelado ou ignorado pelo otimizador)\n",
        "            optimizer_clf = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.classifier.parameters()}\n",
        "            ], lr=self.lr)\n",
        "        else:\n",
        "            # Se for MLP/CNN padrão: Treina todos os parâmetros\n",
        "            optimizer_clf = self.optimizer_class(model.parameters(), lr=self.lr)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "        \n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_start = time.time()\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            for xb, yb in train_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                \n",
        "                # Ajuste de shape\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                optimizer_clf.zero_grad()\n",
        "                outputs = model(xb)\n",
        "\n",
        "                # Cálculo da perda apenas de CLASSIFICAÇÃO\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0] # Pega apenas a classificação\n",
        "                else:\n",
        "                    classification_output = outputs # Modelo padrão\n",
        "\n",
        "                loss = self.criterion(classification_output, yb)\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer_clf.step()\n",
        "                running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "            # Validação\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                    # Ajuste de shape\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    outputs = model(xb)\n",
        "                    \n",
        "                    if isinstance(outputs, tuple):\n",
        "                        classification_output = outputs[0]\n",
        "                    else:\n",
        "                        classification_output = outputs\n",
        "\n",
        "                    loss = self.criterion(classification_output, yb)\n",
        "                    val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "            \n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(avg_val_loss)\n",
        "            \n",
        "            epoch_time = time.time() - epoch_start\n",
        "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                print(f\"  [Supervised] Epoch {epoch+1}/{self.num_epochs} Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(train_losses, label=\"Train Loss (Clf)\")\n",
        "        plt.plot(val_losses, label=\"Val Loss (Clf)\")\n",
        "        plt.legend(); plt.title(f\"Loss Curve - Fold {fold_idx}\")\n",
        "        plt.savefig(os.path.join(self.dir_path, f\"loss_curve_fold{fold_idx}_{self.start_time}.png\")); plt.close()\n",
        "        \n",
        "        torch.save(model_core.state_dict(), os.path.join(self.dir_path, f\"model_fold{fold_idx}.pt\"))\n",
        "\n",
        "        # Teste\n",
        "        y_true, y_pred, y_proba = [], [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                outputs = model(xb)\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0]\n",
        "                else:\n",
        "                    classification_output = outputs\n",
        "\n",
        "                probs = torch.softmax(classification_output, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                y_true.extend(yb.cpu().numpy()); y_pred.extend(preds.cpu().numpy()); y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "        metrics = calculate_metrics(np.array(y_true), np.array(y_pred), np.array(y_proba))\n",
        "        return FoldResults(fold_idx, np.array(y_true), np.array(y_pred), np.array(y_proba), metrics)\n",
        "\n",
        "    def run(self) -> ExperimentResults:\n",
        "        self.start_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.dir_path = os.path.join(self.output_dir, f\"results_{self.name}_{self.start_time}\")\n",
        "        os.makedirs(self.dir_path, exist_ok=True)\n",
        "\n",
        "        results = ExperimentResults(\n",
        "            experiment_name=self.name, description=self.description,\n",
        "            model_name=self.original_model.__class__.__name__, feature_names=None,\n",
        "            config={'n_outer_folds': self.n_outer_folds, 'pretrain_epochs': self.pretrain_epochs, \n",
        "                    'finetune_epochs': self.num_epochs, 'batch_size': self.batch_size, 'lr': self.lr}\n",
        "        )\n",
        "\n",
        "        for outer_fold in range(self.n_outer_folds):\n",
        "            print(f\"\\n=== Outer Fold {outer_fold+1}/{self.n_outer_folds} ===\")\n",
        "            train_mask = self.data_fold_idxs != outer_fold\n",
        "            test_mask = self.data_fold_idxs == outer_fold\n",
        "            \n",
        "            try:\n",
        "                fold_result = self._train_one_fold(self.X[train_mask], self.y[train_mask], self.X[test_mask], self.y[test_mask], outer_fold)\n",
        "                results.add_fold_result(fold_result)\n",
        "                print(f\"  Result: Acc={fold_result.metrics['accuracy']:.4f}, F1={fold_result.metrics['f1']:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in fold {outer_fold}: {e}\")\n",
        "                import traceback; traceback.print_exc()\n",
        "\n",
        "        results.calculate_overall_metrics()\n",
        "        results.save_json(os.path.join(self.dir_path, f\"results.json\"))\n",
        "        print(\"\\n=== Final Results ===\")\n",
        "        print(f\"Mean Accuracy: {results.overall_metrics['accuracy']:.4f}\")\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D MLP adaptado para 12k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP1D_12k(nn.Module):\n",
        "    def __init__(self, input_length: int = 12000, num_classes: int = 4):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Camada adicional para adaptar a entrada de 12000 para 1024 progressivamente\n",
        "        self.adaptation_layers = nn.Sequential(\n",
        "            # 12000 -> 4096\n",
        "            nn.Linear(input_length, 4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.7), # Dropout alto para evitar overfitting na entrada\n",
        "\n",
        "            # 4096 -> 2048\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            # 2048 -> 1024 (Conecta com a arquitetura original)\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        # Arquitetura original:        \n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc5 = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc6 = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc7 = nn.Sequential(\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.flatten(x, 1)\n",
        "        \n",
        "        # Passa pela adaptação primeiro\n",
        "        out = self.adaptation_layers(out)\n",
        "        \n",
        "        # Segue o fluxo normal\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.fc5(out)\n",
        "        out = self.fc6(out)\n",
        "        out = self.fc7(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = MLP1D_12k(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"mlp1d_vibration_12k_optimized\",\n",
        "    description=\"1D MLP for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    pretrain_epochs=0,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEE_ePYwV08q"
      },
      "source": [
        "### 1D AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLqcRhHgWLqV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AE1D_12k(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Autoencoder 1D Adaptado para 12k pontos.\n",
        "    Arquitetura: 12000 -> 512 -> 256 -> 128 -> 64 (Latent) -> 128 -> 256 -> 512 -> 12000.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4, dropout_rate: float = 0.4):\n",
        "        super(AE1D_12k, self).__init__()\n",
        "        \n",
        "        # --- Encoder ---\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Camada 1: Compressão Direta (12000 -> 512)\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada 2: 512 -> 256\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada 3: 256 -> 128\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada Latente: 128 -> 64\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # Simétrico ao encoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Latente -> 128\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 128 -> 256\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 256 -> 512\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Reconstrução Final: 512 -> 12000\n",
        "            nn.Linear(512, input_length)\n",
        "        )\n",
        "\n",
        "        # Classificador (Fine-tuning)\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten para garantir (Batch, 12000)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        # Encoder\n",
        "        latent_features = self.encoder(x)\n",
        "        \n",
        "        # Decoder (Reconstrução do sinal de 12k)\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "        \n",
        "        # Classifier\n",
        "        classification_output = self.classifier(latent_features)\n",
        "        \n",
        "        return classification_output, reconstruction, latent_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67yzEiLJXKKE"
      },
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = AE1D_12k(input_length=input_length, latent_dim=64, num_classes=num_classes)\n",
        "\n",
        "# Defina os critérios\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"ae1d_vibration_combined_loss\",\n",
        "    description=\"1D AE for vibration signals (Combined Loss)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # critério para treinamento do autoencoder\n",
        "    criterion=classification_criterion,                # critério para treinamento do classificador\n",
        "    pretrain_epochs=50,  # Treina Encoder+Decoder apenas com MSELoss\n",
        "    num_epochs=50,       # Treina Encoder+Classifier apenas com CrossEntropy\n",
        "    recon_loss_weight=1.0, # recon_loss_weight pode ser 1.0 (pois é a única loss na fase 1)\n",
        "    batch_size=64,\n",
        "    lr=3e-4\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOiLccpyM4U0"
      },
      "source": [
        "### 1D Sparse AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnpj0Q8oM-1r"
      },
      "outputs": [],
      "source": [
        "class SAE1D_12k(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Sparse Autoencoder 1D adaptado para 12k pontos.\n",
        "    Arquitetura: 12000 -> 512 -> 256 -> 128 -> 64 (Latent).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4):\n",
        "        super(SAE1D_12k, self).__init__()\n",
        "        \n",
        "        # --- Encoder ---\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Camada 1: Compressão Direta (12000 -> 512)\n",
        "            # Redução drástica necessária para viabilidade\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2), # Adicionado Dropout leve\n",
        "\n",
        "            # Camada 2: 512 -> 256\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Camada 3: 256 -> 128\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Camada Latente: 128 -> Latent Dim\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # A Sigmoid é OBRIGATÓRIA para SAE se você usar KL Divergence Loss\n",
        "        # Ela força os neurônios latentes a ficarem entre [0, 1] (probabilidade de ativação)\n",
        "        self.sparsity_activation = nn.Sigmoid()\n",
        "\n",
        "        # --- Decoder ---\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Reconstrução: 512 -> 12000\n",
        "            nn.Linear(512, input_length)\n",
        "        )\n",
        "\n",
        "        # Classificador (Fine-tuning)\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Garante (Batch, 12000)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # 1. Codificação Linear\n",
        "        features = self.encoder(x)\n",
        "        \n",
        "        # 2. Ativação Esparsa (Latent Space)\n",
        "        # Importante: A saída aqui estará entre 0 e 1\n",
        "        latent_features = self.sparsity_activation(features)\n",
        "\n",
        "        # 3. Reconstrução\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "\n",
        "        # 4. Classificação\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        return classification_output, reconstruction, latent_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "model = SAE1D_12k(input_length=input_length, latent_dim=64, num_classes=num_classes)\n",
        "\n",
        "# loss criterions\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"sae1d_vibration_sequential\",\n",
        "    description=\"1D Sparse AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=50,  # Treina Encoder+Decoder com MSE + Esparsidade KL\n",
        "    num_epochs=50,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    sparsity_target=0.05,  # (Rho) Nível de esparsidade desejado (ex: 5% dos neurônios ativos) \n",
        "    sparsity_weight=1.0,   # (Beta) Peso da penalidade KL na perda total\n",
        "    recon_loss_weight=1.0, # Peso da reconstrução (geralmente 1.0 na fase de pré-treino puro)\n",
        "    batch_size=64,\n",
        "    lr=3e-4\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D Denoising AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DAE1D_12k(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Denoising Autoencoder (DAE) adaptado para 12k pontos.\n",
        "    Arquitetura: 12000 -> 512 -> 256 -> 128 -> 64 (Latent).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4, noise_factor: float = 0.5):\n",
        "        super(DAE1D_12k, self).__init__()\n",
        "        self.noise_factor = noise_factor\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Camada 1: Compressão Direta (12000 -> 512)\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Camada 2: 512 -> 256\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            \n",
        "            # Camada 3: 256 -> 128\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            \n",
        "            # Latent\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        # Simétrico\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Reconstrução: 512 -> 12000\n",
        "            nn.Linear(512, input_length)\n",
        "        )\n",
        "\n",
        "        # --- Classificador ---\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (Batch, 12000)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Denoising Injection\n",
        "        if self.training:\n",
        "            # Adiciona ruído apenas durante o treino\n",
        "            noise = torch.randn_like(x) * self.noise_factor\n",
        "            x_noisy = x + noise\n",
        "        else:\n",
        "            x_noisy = x\n",
        "        \n",
        "        # Encoder\n",
        "        latent_features = self.encoder(x_noisy)\n",
        "        \n",
        "        # Decoder\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "        \n",
        "        # Classifier\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        # (Classification, Reconstruction, Latent[Opcional])\n",
        "        return classification_output, reconstruction, latent_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "# noise_factor controla o ruído\n",
        "model = DAE1D_12k(input_length=input_length, latent_dim=64, num_classes=num_classes, noise_factor=0.5)\n",
        "\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "# 4. Configuração do Experimento\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"dae1d_vibration_sequential\",\n",
        "    description=\"1D Denoising AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=100,  # Treina Encoder+Decoder com MSELoss (DAE)\n",
        "    num_epochs=100,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    recon_loss_weight=1.0,\n",
        "    batch_size=64, # Batch grande ajuda na estabilidade do AE\n",
        "    lr=3e-4\n",
        ")\n",
        "\n",
        "# 5. Execução\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_length: int, num_classes: int):\n",
        "        \"\"\"\n",
        "        1D CNN for vibration signal classification.\n",
        "        Args:\n",
        "            input_length: length of the input signal\n",
        "            num_classes: number of output classes\n",
        "        \"\"\"\n",
        "        super(CNN1D, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.pool3 = nn.AdaptiveMaxPool1d(16)  # reduce dynamically to fixed size\n",
        "\n",
        "        # compute flattened size\n",
        "        example_input = torch.zeros(1, 1, input_length)  # [B, C, L]\n",
        "        with torch.no_grad():\n",
        "            x = self.pool1(F.relu(self.bn1(self.conv1(example_input))))\n",
        "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "            flattened_size = x.shape[1] * x.shape[2]\n",
        "\n",
        "        self.fc1 = nn.Linear(flattened_size, 128)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B, L] or [B, 1, L]\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)  # add channel dim\n",
        "\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = CNN1D(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"cnn1d_vibration\",\n",
        "    description=\"1D CNN for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LeNet1D_12k(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=4):\n",
        "        super(LeNet1D_12k, self).__init__()\n",
        "        \n",
        "        # --- Bloco Convolucional 1 ---\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channel, 6, kernel_size=64, stride=4, padding=30),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2), # 3000 -> 1500\n",
        "        )\n",
        "        \n",
        "        # --- Bloco Convolucional 2 ---\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(12) \n",
        "        )\n",
        "        \n",
        "        # --- Classificador (Fully Connected) ---\n",
        "        # Input achatado: 16 canais * 12 pontos = 192 features\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 12, 120), # Tamanho clássico da LeNet-5\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(120, 84), # Tamanho clássico da LeNet-5\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.fc3 = nn.Linear(84, out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Garante dimensão de canal (Batch, 1, 12000)\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = LeNet1D_12k(in_channel=1, out_channel=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"1d_lenet vibration\",\n",
        "    description=\"1D LeNet for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv3x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x1 convolution with padding\"\"\"\n",
        "    return nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv1d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x1(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x1(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm1d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet18_12k(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação da ResNet-18 adaptada para sinais 1D de 12.000 pontos.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length=12000, in_channel=1, num_classes=10):\n",
        "        super(ResNet18_12k, self).__init__()\n",
        "        \n",
        "        # Configuração padrão da ResNet18\n",
        "        block = BasicBlock\n",
        "        layers = [2, 2, 2, 2] # 2 blocos por camada = 18 layers total\n",
        "        \n",
        "        self.inplanes = 64\n",
        "        \n",
        "        # STEM (Camada de Entrada)\n",
        "        # Input: (Batch, 1, 12000)\n",
        "        self.conv1 = nn.Conv1d(in_channel, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # Blocos Residuais\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        \n",
        "        # Classificador\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        # Inicialização de Pesos\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm1d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Tratamento de Dimensão: Garante (Batch, 1, Length)\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        # Stem\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Head\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = ResNet18_12k(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"resnet18_12k_vibration\",\n",
        "    description=\"ResNet18 for Raw Vibration (12k points)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AlexNet1D_12k(nn.Module):\n",
        "    def __init__(self, input_length=12000, in_channel=1, num_classes=10):\n",
        "        super(AlexNet1D_12k, self).__init__()\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            # Conv1: Kernel 11 e Stride 4.\n",
        "            # Reduz entrada 12000 -> ~3000\n",
        "            nn.Conv1d(in_channel, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2), # 3000 -> 1500\n",
        "            \n",
        "            # Conv2\n",
        "            nn.Conv1d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2), # 1500 -> 750\n",
        "            \n",
        "            # Conv3\n",
        "            nn.Conv1d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Conv4\n",
        "            nn.Conv1d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Conv5\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2), # 750 -> 375\n",
        "        )\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(6)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            # 256 canais * 6 dimensão temporal = 1536 features\n",
        "            nn.Linear(256 * 6, 1024), # Mantido 1024 conforme seu código (o paper original usa 4096)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Tratamento de segurança para dimensão (Batch, 1, 12000)\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        \n",
        "        # Flatten robusto\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = AlexNet1D_12k(input_length=input_length, in_channel=1, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"alexNet_12k_vibration\",\n",
        "    description=\"AlexNet for Raw Vibration (12k points)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BiLSTM_12k(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=10):\n",
        "        super(BiLSTM_12k, self).__init__()\n",
        "        \n",
        "        # Hiperparâmetros Internos\n",
        "        self.hidden_dim = 64\n",
        "        self.kernel_num = 16\n",
        "        self.num_layers = 2\n",
        "        \n",
        "        # self.V define o comprimento da sequência que entra na LSTM\n",
        "        self.V = 100 \n",
        "\n",
        "        # Camada de stem\n",
        "        self.embed1 = nn.Sequential(\n",
        "            # Kernel grande e Stride 4 para lidar com alta taxa de amostragem\n",
        "            nn.Conv1d(in_channel, self.kernel_num, kernel_size=64, stride=4, padding=30),\n",
        "            nn.BatchNorm1d(self.kernel_num),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
        "        )\n",
        "        \n",
        "        self.embed2 = nn.Sequential(\n",
        "            nn.Conv1d(self.kernel_num, self.kernel_num*2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(self.kernel_num*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # AdaptiveMaxPool força a saída a ter exatamente comprimento self.V (100) garantindo entrada constante para a LSTM\n",
        "            nn.AdaptiveMaxPool1d(self.V)\n",
        "        )\n",
        "        \n",
        "        # Camada Recorrente (BiLSTM)\n",
        "        # Input Size: kernel_num*2 (32 features por passo de tempo)\n",
        "        self.bilstm = nn.LSTM(\n",
        "            input_size=self.kernel_num*2, \n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=self.num_layers, \n",
        "            bidirectional=True,\n",
        "            batch_first=True, \n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Classificador\n",
        "        # O input da linear é: Comprimento da Sequência (V) * (Hidden * 2 direções)\n",
        "        self.hidden2label1 = nn.Sequential(\n",
        "            nn.Linear(self.V * 2 * self.hidden_dim, 512),\n",
        "            nn.ReLU(), \n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        \n",
        "        self.hidden2label2 = nn.Linear(512, out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (Batch, 1, 12000)\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        # Extração de Features Convolucionais\n",
        "        x = self.embed1(x)\n",
        "        x = self.embed2(x) \n",
        "        # (Batch, 32, 100) -> (Batch, Channels, Time)\n",
        "        \n",
        "        # Preparação para LSTM\n",
        "        # LSTM espera (Batch, Time, Features/Channels)\n",
        "        x = x.permute(0, 2, 1) # (Batch, 100, 32)\n",
        "        \n",
        "        # Processamento Recorrente\n",
        "        bilstm_out, _ = self.bilstm(x)\n",
        "        bilstm_out = torch.tanh(bilstm_out)\n",
        "        \n",
        "        # Classificação\n",
        "        bilstm_out = bilstm_out.reshape(bilstm_out.size(0), -1)\n",
        "        \n",
        "        logit = self.hidden2label1(bilstm_out)\n",
        "        logit = self.hidden2label2(logit)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = BiLSTM_12k(in_channel=1, out_channel=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"BiLSTM_12k_vibration\",\n",
        "    description=\"BiLSTM for Raw Vibration (12k points)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.show_results()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PPXmkt-iKCeA",
        "Bt4WUe1EkNUQ",
        "pEE_ePYwV08q",
        "9RzAtB1FtI1t",
        "5y2zAwCJuAkM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
