{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPXmkt-iKCeA"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTHYLssWfNUu",
        "outputId": "46bb7f4e-522c-4898-b1bc-ecc7024b2b03"
      },
      "outputs": [],
      "source": [
        "!pip install vibdata==1.1.1 signalAI==0.0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGC5F4WuQ8Qs"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "6pod38v0RKKx",
        "outputId": "c37ec1db-237c-41f3-b7a1-1c31d3eb7326"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import vibdata.raw as raw_datasets\n",
        "from vibdata.deep.DeepDataset import DeepDataset, convertDataset\n",
        "from vibdata.deep.signal.transforms import (\n",
        "    Sequential,\n",
        "    SplitSampleRate,\n",
        "    FeatureExtractor,\n",
        "    FilterByValue,\n",
        ")\n",
        "from vibdata.deep.signal.core import SignalSample\n",
        "\n",
        "# from signalAI.experiments.torch_data import DeepLearningExperiment\n",
        "from signalAI.experiments.features_1d import Features1DExperiment\n",
        "from signalAI.utils.group_dataset import GroupDataset\n",
        "from signalAI.utils.fold_idx_generator import (\n",
        "    FoldIdxGeneratorUnbiased,\n",
        "    FoldIdxGeneratorBiased,\n",
        ")\n",
        "\n",
        "class GroupCWRULoad(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        return sample[\"metainfo\"][\"load\"]\n",
        "\n",
        "class GroupCWRUSeverity(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        severity = sample[\"metainfo\"][\"fault_size\"]\n",
        "\n",
        "        match severity:\n",
        "            case 0.0:\n",
        "                return sample[\"metainfo\"][\"load\"]\n",
        "            case 0.007:\n",
        "                return 0\n",
        "            case 0.014:\n",
        "                return 1\n",
        "            case 0.021:\n",
        "                return 2\n",
        "            case 0.028:\n",
        "                return 3\n",
        "\n",
        "        return None\n",
        "\n",
        "'''\n",
        "class GroupMultiRoundCWRULoad(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        sample_metainfo = sample[\"metainfo\"]\n",
        "        return sample_metainfo[\"label\"].astype(str) + \" \" + sample_metainfo[\"load\"].astype(int).astype(str)\n",
        "\n",
        "CLASS_DEF = {0: \"N\", 1: \"O\", 2: \"I\", 3: \"R\"}\n",
        "CONDITION_DEF = {\"0\": \"0\", \"1\": \"1\", \"2\": \"2\", \"3\": \"3\"}\n",
        "folds_multiround = FoldIdxGeneratorUnbiased(deep_dataset,\n",
        "                                    GroupMultiRoundCWRULoad ,\n",
        "                                    dataset_name=\"CWRU\",\n",
        "                                    multiround=True,\n",
        "                                    class_def=CLASS_DEF,\n",
        "                                    condition_def=CONDITION_DEF).generate_folds()\n",
        "folds_multiround\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gw9EnsSs276"
      },
      "source": [
        "# Deep Learning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRt2UWNpaPbh"
      },
      "source": [
        "## Import CRWU dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cckVlJSzUqnN"
      },
      "outputs": [],
      "source": [
        "# Get raw root_dir\n",
        "raw_root_dir = \"../data/raw_data/cwru\"\n",
        "raw_dataset = raw_datasets.CWRU_raw(raw_root_dir, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rDx-9rht7Un"
      },
      "source": [
        "## Time domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmIzuXr-aVBm"
      },
      "source": [
        "### 12k SampleRate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t09LPCnRtMbu",
        "outputId": "6aa32f9b-c9b5-4eb0-9507-1a6894c56c17"
      },
      "outputs": [],
      "source": [
        "transforms_time = Sequential(\n",
        "    [\n",
        "        SplitSampleRate(),\n",
        "    ]\n",
        ")\n",
        "print(transforms_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NeeJ_8J3tRno"
      },
      "outputs": [],
      "source": [
        "deep_root_dir_time = \"../data/deep_data/deep_learning\"\n",
        "deep_dataset_time = convertDataset(raw_dataset,filter=FilterByValue(on_field=\"sample_rate\", values=12000),transforms=transforms_time, dir_path=deep_root_dir_time, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gufU833iax3I"
      },
      "source": [
        "## Generate Unbiased Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd86Qz_Qth8u",
        "outputId": "74a72abc-7c83-4872-e1f3-7e698abb2344"
      },
      "outputs": [],
      "source": [
        "folds_singleround_deep = FoldIdxGeneratorUnbiased(deep_dataset_time, GroupCWRULoad , dataset_name=\"CWRU12k_deep\").generate_folds()\n",
        "folds_singleround_deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Biased Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folds_singleround_deep = FoldIdxGeneratorBiased(deep_dataset_time, dataset_name=\"CWRU12k_deep\", n_folds=4).generate_folds()\n",
        "folds_singleround_deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1DdMvqe7Qs"
      },
      "source": [
        "## DeepLearning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt4WUe1EkNUQ"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Sbq0v5_lgAAW"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/base.py\n",
        "from abc import ABC, abstractmethod\n",
        "import json\n",
        "from typing import Optional, Dict, Any\n",
        "from vibdata.raw.base import RawVibrationDataset\n",
        "from vibdata.deep.signal.transforms import Transform\n",
        "\n",
        "class Experiment(ABC):\n",
        "    \"\"\"Classe base abstrata para todos os experimentos de classificação de vibração.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset: Optional[RawVibrationDataset] = None,\n",
        "        data_transform: Optional[Transform] = None,\n",
        "        feature_selector = None,\n",
        "        model = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Inicializa o experimento.\n",
        "\n",
        "        Args:\n",
        "            name: Nome identificador do experimento\n",
        "            description: Descrição detalhada do experimento\n",
        "            dataset: Conjunto de dados de vibração\n",
        "            data_transform: Transformação a ser aplicada nos dados brutos\n",
        "            data_division_method: Método de divisão dos dados (e.g., 'kfold', 'holdout')\n",
        "            data_division_params: Parâmetros para o método de divisão\n",
        "            feature_selector: Seletor de features (para experimentos com extração)\n",
        "            model: Modelo de machine learning/deep learning\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.dataset = dataset\n",
        "        self.data_transform = data_transform\n",
        "        self.feature_selector = feature_selector\n",
        "        self.model = model\n",
        "\n",
        "        # Resultados serão armazenados aqui\n",
        "        self.results = {}\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepara os dados para o experimento.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self):\n",
        "        \"\"\"Executa o experimento completo.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def save_results(self, filepath: str):\n",
        "        \"\"\"Salva os resultados do experimento.\"\"\"\n",
        "        # Implementação básica - pode ser extendida\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(self.results, f)\n",
        "\n",
        "    def load_results(self, filepath: str):\n",
        "        \"\"\"Carrega resultados de um experimento anterior.\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            self.results = json.load(f)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Experiment: {self.name}\\nDescription: {self.description}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pS8nDnOpe_Le"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/deep_torch.py\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Tuple, Union\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from signalAI.utils.metrics import calculate_metrics\n",
        "from signalAI.utils.experiment_result import ExperimentResults, FoldResults\n",
        "import copy\n",
        "\n",
        "class TorchVibrationDataset(Dataset):\n",
        "    \"\"\"Wrapper to convert dataset samples into Torch tensors.\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Função auxiliar KL\n",
        "def kl_divergence(rho, rho_hat):\n",
        "    rho_hat = torch.mean(rho_hat, dim=0)\n",
        "    rho = torch.tensor([rho] * len(rho_hat), device=rho_hat.device)\n",
        "    epsilon = 1e-7\n",
        "    term1 = rho * torch.log((rho + epsilon) / (rho_hat + epsilon))\n",
        "    term2 = (1 - rho) * torch.log((1 - rho + epsilon) / (1 - rho_hat + epsilon))\n",
        "    return torch.sum(term1 + term2)\n",
        "\n",
        "class DeepLearningExperiment(Experiment):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset,\n",
        "        data_fold_idxs: List[int],\n",
        "        model: nn.Module,\n",
        "        criterion: Optional[nn.Module] = None,\n",
        "        # Parâmetros adaptados para o autoencoder\n",
        "        reconstruction_criterion: Optional[nn.Module] = None,\n",
        "        recon_loss_weight: float = 1.0,\n",
        "        sparsity_target: Optional[float] = None,\n",
        "        sparsity_weight: float = 0.0,\n",
        "        pretrain_epochs: int = 0, # Épocas de treinamento do autoencoder\n",
        "        optimizer_class: Optional[torch.optim.Optimizer] = optim.Adam,\n",
        "        batch_size: int = 32,\n",
        "        lr: float = 1e-3,\n",
        "        num_epochs: int = 20, # Épocas de treino do classificador\n",
        "        val_split: float = 0.2,\n",
        "        output_dir: str = \"results_torch\",\n",
        "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(name, description, dataset, model=model, **kwargs)\n",
        "        self.data_fold_idxs = data_fold_idxs\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.pretrain_epochs = pretrain_epochs\n",
        "        self.val_split = val_split\n",
        "        self.device = device\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.lr = lr\n",
        "        self.criterion = criterion if criterion is not None else nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.reconstruction_criterion = reconstruction_criterion\n",
        "        self.recon_loss_weight = recon_loss_weight\n",
        "        self.sparsity_target = sparsity_target\n",
        "        self.sparsity_weight = sparsity_weight\n",
        "        \n",
        "        self.is_sae_task = self.sparsity_target is not None and self.sparsity_weight > 0.0\n",
        "        # Define tipo do AutoEncoder utilizado\n",
        "        self.is_autoencoder_task = reconstruction_criterion is not None or self.is_sae_task or \"AE1D\" in model.__class__.__name__\n",
        "\n",
        "        if self.is_sae_task and self.reconstruction_criterion is None:\n",
        "             print(\"Warning: SAE task detected but no reconstruction_criterion. Defaulting to MSELoss.\")\n",
        "             self.reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
        "            model = torch.nn.DataParallel(model) \n",
        "        \n",
        "        # Guarda encoder e decoder\n",
        "        self.original_model = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        self.n_outer_folds = len(np.unique(data_fold_idxs))\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        features, labels = [], []\n",
        "        for sample in self.dataset:\n",
        "            features.append(sample['signal'][0]) \n",
        "            labels.append(sample['metainfo']['label'])\n",
        "        self.X = np.array(features)\n",
        "        self.y = np.array(labels)\n",
        "\n",
        "    def _train_one_fold(\n",
        "        self, X_train, y_train, X_test, y_test, fold_idx: int\n",
        "    ) -> FoldResults:\n",
        "        \n",
        "        train_dataset = TorchVibrationDataset(X_train, y_train)\n",
        "        test_dataset = TorchVibrationDataset(X_test, y_test)\n",
        "        val_size = int(self.val_split * len(train_dataset))\n",
        "        train_size = len(train_dataset) - val_size\n",
        "        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        model = copy.deepcopy(self.model.to(self.device))\n",
        "        model_core = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        # Verificação da estrutura de AE (encoder, decoder, classifier)\n",
        "        has_ae_structure = hasattr(model_core, 'encoder') and hasattr(model_core, 'decoder') and hasattr(model_core, 'classifier')\n",
        "\n",
        "        # ============================================================\n",
        "        # TREINO DO AUTOENCODER\n",
        "        # ============================================================\n",
        "        if self.is_autoencoder_task and self.pretrain_epochs > 0 and has_ae_structure:\n",
        "            print(f\"[Fold {fold_idx}] AutoEncoder training ({self.pretrain_epochs} epochs)...\")\n",
        "            \n",
        "            # Otimizador Encoder + Decoder\n",
        "            optimizer_ae = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.decoder.parameters()}\n",
        "            ], lr=self.lr)\n",
        "\n",
        "            for epoch in range(self.pretrain_epochs):\n",
        "                model.train()\n",
        "                running_recon_loss = 0.0\n",
        "                \n",
        "                for xb, _ in train_loader:\n",
        "                    xb = xb.to(self.device)\n",
        "                    input_data = xb\n",
        "\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                        xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    optimizer_ae.zero_grad()\n",
        "                    outputs = model(xb) # (class, recon, [sparsity])\n",
        "\n",
        "                    if isinstance(outputs, tuple):\n",
        "                        # Foco na reconstrução\n",
        "                        reconstruction = outputs[1] \n",
        "                        \n",
        "                        loss = self.reconstruction_criterion(reconstruction, input_data)\n",
        "                        \n",
        "                        # Adiciona esparsidade se for SAE\n",
        "                        if self.is_sae_task and len(outputs) > 2:\n",
        "                            latent_features = outputs[2]\n",
        "                            loss += self.sparsity_weight * kl_divergence(self.sparsity_target, latent_features)\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer_ae.step()\n",
        "                        running_recon_loss += loss.item() * input_data.size(0)\n",
        "                \n",
        "                avg_recon_loss = running_recon_loss / len(train_loader.dataset)\n",
        "                if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                    print(f\"  [Pre-train] Epoch {epoch+1}/{self.pretrain_epochs} Recon Loss: {avg_recon_loss:.4f}\")\n",
        "\n",
        "        # ============================================================\n",
        "        # TREINO DO CLASSIFICADOR\n",
        "        # ============================================================\n",
        "        print(f\"[Fold {fold_idx}] Classifier training ({self.num_epochs} epochs)...\")\n",
        "\n",
        "        # Define otimizador para a fase supervisionada\n",
        "        if has_ae_structure and self.is_autoencoder_task:\n",
        "            # Se for AE: Treina Encoder + Classifier (Decoder congelado ou ignorado pelo otimizador)\n",
        "            optimizer_clf = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.classifier.parameters()}\n",
        "            ], lr=self.lr)\n",
        "        else:\n",
        "            # Se for MLP/CNN padrão: Treina todos os parâmetros\n",
        "            optimizer_clf = self.optimizer_class(model.parameters(), lr=self.lr)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "        \n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_start = time.time()\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            for xb, yb in train_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                \n",
        "                # Ajuste de shape\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                optimizer_clf.zero_grad()\n",
        "                outputs = model(xb)\n",
        "\n",
        "                # Cálculo da perda apenas de CLASSIFICAÇÃO\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0] # Pega apenas a classificação\n",
        "                else:\n",
        "                    classification_output = outputs # Modelo padrão\n",
        "\n",
        "                loss = self.criterion(classification_output, yb)\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer_clf.step()\n",
        "                running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "            # Validação\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                    # Ajuste de shape\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    outputs = model(xb)\n",
        "                    \n",
        "                    if isinstance(outputs, tuple):\n",
        "                        classification_output = outputs[0]\n",
        "                    else:\n",
        "                        classification_output = outputs\n",
        "\n",
        "                    loss = self.criterion(classification_output, yb)\n",
        "                    val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "            \n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(avg_val_loss)\n",
        "            \n",
        "            epoch_time = time.time() - epoch_start\n",
        "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                print(f\"  [Supervised] Epoch {epoch+1}/{self.num_epochs} Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(train_losses, label=\"Train Loss (Clf)\")\n",
        "        plt.plot(val_losses, label=\"Val Loss (Clf)\")\n",
        "        plt.legend(); plt.title(f\"Loss Curve - Fold {fold_idx}\")\n",
        "        plt.savefig(os.path.join(self.dir_path, f\"loss_curve_fold{fold_idx}_{self.start_time}.png\")); plt.close()\n",
        "        \n",
        "        torch.save(model_core.state_dict(), os.path.join(self.dir_path, f\"model_fold{fold_idx}.pt\"))\n",
        "\n",
        "        # Teste\n",
        "        y_true, y_pred, y_proba = [], [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                outputs = model(xb)\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0]\n",
        "                else:\n",
        "                    classification_output = outputs\n",
        "\n",
        "                probs = torch.softmax(classification_output, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                y_true.extend(yb.cpu().numpy()); y_pred.extend(preds.cpu().numpy()); y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "        metrics = calculate_metrics(np.array(y_true), np.array(y_pred), np.array(y_proba))\n",
        "        return FoldResults(fold_idx, np.array(y_true), np.array(y_pred), np.array(y_proba), metrics)\n",
        "\n",
        "    def run(self) -> ExperimentResults:\n",
        "        self.start_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.dir_path = os.path.join(self.output_dir, f\"results_{self.name}_{self.start_time}\")\n",
        "        os.makedirs(self.dir_path, exist_ok=True)\n",
        "\n",
        "        results = ExperimentResults(\n",
        "            experiment_name=self.name, description=self.description,\n",
        "            model_name=self.original_model.__class__.__name__, feature_names=None,\n",
        "            config={'n_outer_folds': self.n_outer_folds, 'pretrain_epochs': self.pretrain_epochs, \n",
        "                    'finetune_epochs': self.num_epochs, 'batch_size': self.batch_size, 'lr': self.lr}\n",
        "        )\n",
        "\n",
        "        for outer_fold in range(self.n_outer_folds):\n",
        "            print(f\"\\n=== Outer Fold {outer_fold+1}/{self.n_outer_folds} ===\")\n",
        "            train_mask = self.data_fold_idxs != outer_fold\n",
        "            test_mask = self.data_fold_idxs == outer_fold\n",
        "            \n",
        "            try:\n",
        "                fold_result = self._train_one_fold(self.X[train_mask], self.y[train_mask], self.X[test_mask], self.y[test_mask], outer_fold)\n",
        "                results.add_fold_result(fold_result)\n",
        "                print(f\"  Result: Acc={fold_result.metrics['accuracy']:.4f}, F1={fold_result.metrics['f1']:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in fold {outer_fold}: {e}\")\n",
        "                import traceback; traceback.print_exc()\n",
        "\n",
        "        results.calculate_overall_metrics()\n",
        "        results.save_json(os.path.join(self.dir_path, f\"results.json\"))\n",
        "        print(\"\\n=== Final Results ===\")\n",
        "        print(f\"Mean Accuracy: {results.overall_metrics['accuracy']:.4f}\")\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PboZEAgOtN2R"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1u8Zh-uiXFB"
      },
      "source": [
        "#### Adaptação com mais camadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DLbeBdTtP7U"
      },
      "outputs": [],
      "source": [
        "class MLP1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do MLP baseado na Figura 2 do artigo\n",
        "    Projetado para entrada 1D com 1024 features.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int, num_classes: int, dropout_rate: float = 0.5):\n",
        "        super(MLP1D, self).__init__()\n",
        "\n",
        "        # O artigo especifica 5 camadas FC+BN, mas como a entrada é de tamanho 12000 são utilizadas mais camadas\n",
        "        # Os tamanhos de feature são: 12000 -> 8192 -> 4096 -> 2048 -> 1024 -> 512 -> 256 -> 128 -> 64\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_length, 8192),\n",
        "            nn.BatchNorm1d(8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(8192, 4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.layers(x)\n",
        "        output = self.classifier(features)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9VqcpmvqsES"
      },
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = MLP1D(input_length=input_length, num_classes=num_classes, dropout_rate=0.5)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"mlp1d_vibration\",\n",
        "    description=\"1D MLP for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indices\n",
        "    model=model,\n",
        "    batch_size=2048,\n",
        "    lr=1e-3,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyShZBYQiboZ"
      },
      "source": [
        "#### Arquitetura original do artigo adicinando dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xom4SBV4ifnm"
      },
      "outputs": [],
      "source": [
        "class MLP1D_paper(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação de um MLP baseline razoável para entrada de 12000.\n",
        "    A arquitetura segue a Figura 2 do artigo,\n",
        "    adaptando apenas a primeira camada e adicionando Dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, num_classes: int = 4, dropout_rate: float = 0.4):\n",
        "        super(MLP1D_paper, self).__init__()\n",
        "\n",
        "        # Arquitetura de 5 camadas ocultas inspirada no artigo\n",
        "        # 12000 -> 1024 -> 512 -> 256 -> 128 -> 64\n",
        "        self.layers = nn.Sequential(\n",
        "            # 1. Camada de entrada adaptada\n",
        "            nn.Linear(input_length, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate), # Dropout para regularizar a 1ª camada grande\n",
        "\n",
        "            # 2. Camadas ocultas seguintes\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # 3.\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # 4.\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # 5. Camada final de features\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Classificador separado\n",
        "        self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x deve ter a forma [batch_size, input_length]\n",
        "        features = self.layers(x)\n",
        "        output = self.classifier(features)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFOzfg7Atozy",
        "outputId": "78ab4e89-dbdc-4024-d25d-50d2db5745a3"
      },
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = MLP1D_paper(input_length=input_length, num_classes=num_classes, dropout_rate=0.5)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"mlp1d_vibration\",\n",
        "    description=\"1D MLP for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=2048,\n",
        "    lr=1e-3,\n",
        "    pretrain_epochs=0,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEE_ePYwV08q"
      },
      "source": [
        "### 1D AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yLqcRhHgWLqV"
      },
      "outputs": [],
      "source": [
        "class AE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação de um Autoencoder 1D com Dropout para regularização,\n",
        "    adaptado para uma entrada de comprimento 12000 e incluindo um classificador.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4, dropout_rate: float = 0.4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_length: Comprimento do sinal de entrada.\n",
        "            latent_dim: Dimensão do espaço latente.\n",
        "            num_classes: Número de classes para classificação.\n",
        "            dropout_rate: Probabilidade de um neurônio ser zerado (ex: 0.4 = 40%).\n",
        "        \"\"\"\n",
        "        super(AE1D, self).__init__()\n",
        "        self.input_length = input_length\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # --- Encoder ---\n",
        "        # Adicionadas camadas nn.Dropout após cada nn.ReLU\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_length, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada final do encoder para o espaço latente\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # Adicionadas camadas nn.Dropout após cada nn.ReLU\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada final do decoder (sem dropout)\n",
        "            nn.Linear(1024, input_length)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o passo forward. (Permanece inalterado)\n",
        "        A entrada x deve ter a forma [batch_size, input_length].\n",
        "        \"\"\"\n",
        "        # Codifica a entrada para o espaço latente\n",
        "        latent_features = self.encoder(x)\n",
        "\n",
        "        # Decodifica do espaço latente para reconstruir a entrada\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "\n",
        "        # Classifica a partir do espaço latente\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        # Retorna a saída da classificação e a reconstrução\n",
        "        return classification_output, reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "67yzEiLJXKKE"
      },
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = AE1D(input_length=input_length, latent_dim=64, num_classes=num_classes, dropout_rate=0.5)\n",
        "\n",
        "# Defina os critérios\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"ae1d_vibration_combined_loss\",\n",
        "    description=\"1D AE for vibration signals (Combined Loss)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # critério para treinamento do autoencoder\n",
        "    criterion=classification_criterion,                # critério para treinamento do classificador\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder apenas com MSELoss\n",
        "    num_epochs=10,       # Treina Encoder+Classifier apenas com CrossEntropy\n",
        "    recon_loss_weight=1.0, # recon_loss_weight pode ser 1.0 (pois é a única loss na fase 1)\n",
        "    batch_size=2048,\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOiLccpyM4U0"
      },
      "source": [
        "### 1D Sparse AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rnpj0Q8oM-1r"
      },
      "outputs": [],
      "source": [
        "class SAE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação de um Sparse Autoencoder 1D baseado em camadas lineares,\n",
        "    adaptado para uma entrada de comprimento 12000 e incluindo um classificador.\n",
        "    A esparsidade é aplicada externamente via perda KL na camada latente.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_length: Comprimento do sinal de entrada.\n",
        "            latent_dim: Dimensão do espaço latente (onde a esparsidade será aplicada).\n",
        "            num_classes: Número de classes para classificação.\n",
        "        \"\"\"\n",
        "        super(SAE1D, self).__init__()\n",
        "        self.input_length = input_length\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_length, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128), nn.BatchNorm1d(128), nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 256), nn.BatchNorm1d(256), nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, input_length)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "        self.sparsity_activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o passo forward.\n",
        "        Retorna: (saída da classificação, reconstrução, ativações latentes para esparsidade)\n",
        "        \"\"\"\n",
        "        latent_features_raw = self.encoder(x) # Saída linear do encoder\n",
        "\n",
        "        # Aplica Sigmoid para o cálculo da esparsidade\n",
        "        latent_features_for_sparsity = self.sparsity_activation(latent_features_raw)\n",
        "\n",
        "        reconstruction = self.decoder(latent_features_raw) # Decoder usa a saída linear\n",
        "        classification_output = self.classifier(latent_features_raw) # Classifier usa a saída linear\n",
        "\n",
        "        # Retorna as 3 componentes necessárias\n",
        "        return classification_output, reconstruction, latent_features_for_sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "model = SAE1D(input_length=input_length, latent_dim=64, num_classes=num_classes)\n",
        "\n",
        "# loss criterions\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"sae1d_vibration_sequential\",\n",
        "    description=\"1D Sparse AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder com MSE + Esparsidade KL\n",
        "    num_epochs=10,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    sparsity_target=0.05,  # (Rho) Nível de esparsidade desejado (ex: 5% dos neurônios ativos) \n",
        "    sparsity_weight=0.1,   # (Beta) Peso da penalidade KL na perda total\n",
        "    recon_loss_weight=1.0, # Peso da reconstrução (geralmente 1.0 na fase de pré-treino puro)\n",
        "    batch_size=2048,\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D Denoising AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DAE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação de um Denoising Autoencoder (DAE) 1D.\n",
        "    Adaptação para entrada de comprimento 12000 e incluindo um classificador.\n",
        "    O DAE adiciona ruído Gaussiano à entrada durante o treinamento para aprender a reconstruir sinais limpos.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 12000, latent_dim: int = 64, num_classes: int = 4, noise_factor: float = 0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_length: Comprimento do sinal de entrada.\n",
        "            latent_dim: Dimensão do espaço latente.\n",
        "            num_classes: Número de classes para classificação.\n",
        "            noise_factor: Fator de intensidade do ruído Gaussiano (desvio padrão).\n",
        "        \"\"\"\n",
        "        super(DAE1D, self).__init__()\n",
        "        self.input_length = input_length\n",
        "        self.latent_dim = latent_dim\n",
        "        self.noise_factor = noise_factor\n",
        "\n",
        "        # --- Encoder ---\n",
        "        # Recebe a entrada (potencialmente ruidosa) e comprime\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_length, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, latent_dim) \n",
        "        )\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # Tenta reconstruir o sinal limpo a partir do latente\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128), nn.BatchNorm1d(128), nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 256), nn.BatchNorm1d(256), nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, input_length)\n",
        "        )\n",
        "\n",
        "        # --- Classifier ---\n",
        "        # Classifica com base nas features latentes\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o passo forward.\n",
        "        Args:\n",
        "            x: Entrada limpa (batch_size, input_length)\n",
        "        Returns:\n",
        "            classification_output: Logits para classificação\n",
        "            reconstruction: Sinal reconstruído (tentativa de remover ruído)\n",
        "        \"\"\"\n",
        "        \n",
        "        # adiciona ruído gaussiano apenas durante o treinamento\n",
        "        if self.training:\n",
        "            noise = torch.randn_like(x) * self.noise_factor\n",
        "            x_noisy = x + noise\n",
        "        else:\n",
        "            x_noisy = x\n",
        "\n",
        "        # Encoder processa a entrada com ruído (\"input + noise\")\n",
        "        latent_features = self.encoder(x_noisy)\n",
        "\n",
        "        # Decoder tenta reconstruir a entrada limpa\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "\n",
        "        # Classificador usa as features latentes\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        return classification_output, reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "# noise_factor controla o ruído\n",
        "model = DAE1D(input_length=input_length, latent_dim=64, num_classes=num_classes, noise_factor=0.5)\n",
        "\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "# 4. Configuração do Experimento\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"dae1d_vibration_sequential\",\n",
        "    description=\"1D Denoising AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder com MSELoss (DAE)\n",
        "    num_epochs=10,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    recon_loss_weight=1.0,\n",
        "    batch_size=2048, # Batch grande ajuda na estabilidade do AE\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "# 5. Execução\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RzAtB1FtI1t"
      },
      "source": [
        "### 1D CNN (Exemplo aula)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eh7NALxItkhZ"
      },
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_length: int, num_classes: int):\n",
        "        \"\"\"\n",
        "        Simple 1D CNN for vibration signal classification.\n",
        "\n",
        "        Args:\n",
        "            input_length: length of the input signal\n",
        "            num_classes: number of output classes\n",
        "        \"\"\"\n",
        "        super(CNN1D, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.pool3 = nn.AdaptiveMaxPool1d(16)  # reduce dynamically to fixed size\n",
        "\n",
        "        # compute flattened size\n",
        "        example_input = torch.zeros(1, 1, input_length)  # [B, C, L]\n",
        "        with torch.no_grad():\n",
        "            x = self.pool1(F.relu(self.bn1(self.conv1(example_input))))\n",
        "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "            flattened_size = x.shape[1] * x.shape[2]\n",
        "\n",
        "        self.fc1 = nn.Linear(flattened_size, 128)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B, L] or [B, 1, L]\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)  # add channel dim\n",
        "\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6wU2ECGKeKlO"
      },
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = CNN1D(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"cnn1d_vibration\",\n",
        "    description=\"1D CNN for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=1e-3,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D CNN (7 layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gH40Mtt9RyYs"
      },
      "outputs": [],
      "source": [
        "class CNN1D_7Layers(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação da 1D CNN (7 layers) baseada no artigo.\n",
        "    Estrutura:\n",
        "    - Bloco 1: 2x(Conv + BN) + MaxPool\n",
        "    - Bloco 2: 2x(Conv + BN) + AdaptiveMaxPool\n",
        "    - Classificador: 3x FC (Fully Connected)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, num_classes: int = 10):\n",
        "        super(CNN1D_7Layers, self).__init__()\n",
        "        \n",
        "        # block 1\n",
        "        self.block1 = nn.Sequential(\n",
        "            # 1ª Convolução: 1 canal -> 16 canais\n",
        "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=15, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # 2ª Convolução: 16 canais -> 32 canais\n",
        "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # MaxPool: Reduz pela metade a dimensão temporal\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        # block 2        \n",
        "        self.block2 = nn.Sequential(\n",
        "            # 3ª Convolução: 32 canais -> 64 canais\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # 4ª Convolução: 64 canais -> 128 canais\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Adaptive MaxPool: Reduz dimensão temporal para tamanho fixo 4\n",
        "            nn.AdaptiveMaxPool1d(output_size=4)\n",
        "        )\n",
        "        \n",
        "        # classificador\n",
        "        # Input achatado: 128 canais * 4 dimensão temporal = 512 features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # 1ª FC: Entrada 512 (4*128) -> Saída 256\n",
        "            nn.Linear(128 * 4, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # O artigo usa Dropout nessas camadas\n",
        "            nn.Dropout(0.5), \n",
        "            \n",
        "            # 2ª FC: 256 -> 64\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            # 3ª FC (Saída): 64 -> Num_class\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ajuste de forma para garantir [Batch, 1, Length]\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        # block 1\n",
        "        x = self.block1(x)\n",
        "        \n",
        "        # block 2\n",
        "        x = self.block2(x)\n",
        "        \n",
        "        # classificador\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = CNN1D_7Layers(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"cnn1d_7layers_vibration\",\n",
        "    description=\"1D CNN (7 Layers) for vibration signals (Standard Supervised)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    batch_size=64, \n",
        "    lr=1e-3,       \n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PPXmkt-iKCeA",
        "Bt4WUe1EkNUQ",
        "pEE_ePYwV08q",
        "9RzAtB1FtI1t",
        "5y2zAwCJuAkM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
