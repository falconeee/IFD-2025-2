{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPXmkt-iKCeA"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTHYLssWfNUu",
        "outputId": "46bb7f4e-522c-4898-b1bc-ecc7024b2b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vibdata==1.1.1\n",
            "  Downloading vibdata-1.1.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting signalAI==0.0.4\n",
            "  Downloading signalAI-0.0.4-py3-none-any.whl.metadata (446 bytes)\n",
            "Collecting essentia (from vibdata==1.1.1)\n",
            "  Downloading essentia-2.1b6.dev1389-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (5.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (2.2.2)\n",
            "Collecting rarfile (from vibdata==1.1.1)\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vibdata==1.1.1) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from signalAI==0.0.4) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from signalAI==0.0.4) (0.13.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from essentia->vibdata==1.1.1) (6.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from essentia->vibdata==1.1.1) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->vibdata==1.1.1) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown->vibdata==1.1.1) (3.20.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->signalAI==0.0.4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->vibdata==1.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->vibdata==1.1.1) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vibdata==1.1.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vibdata==1.1.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vibdata==1.1.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vibdata==1.1.1) (2026.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->vibdata==1.1.1) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->vibdata==1.1.1) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->vibdata==1.1.1) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->vibdata==1.1.1) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->vibdata==1.1.1) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->vibdata==1.1.1) (3.0.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->vibdata==1.1.1) (1.7.1)\n",
            "Downloading vibdata-1.1.1-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading signalAI-0.0.4-py3-none-any.whl (16 kB)\n",
            "Downloading essentia-2.1b6.dev1389-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile, essentia, vibdata, signalAI\n",
            "Successfully installed essentia-2.1b6.dev1389 rarfile-4.2 signalAI-0.0.4 vibdata-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install vibdata==1.1.1 signalAI==0.0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGC5F4WuQ8Qs"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "6pod38v0RKKx",
        "outputId": "c37ec1db-237c-41f3-b7a1-1c31d3eb7326"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import vibdata.raw as raw_datasets\n",
        "from vibdata.deep.DeepDataset import DeepDataset, convertDataset\n",
        "from vibdata.deep.signal.transforms import (\n",
        "    Sequential,\n",
        "    SplitSampleRate,\n",
        "    FeatureExtractor,\n",
        "    FilterByValue,\n",
        "    Split\n",
        ")\n",
        "from vibdata.deep.signal.core import SignalSample\n",
        "\n",
        "# from signalAI.experiments.torch_data import DeepLearningExperiment\n",
        "from signalAI.experiments.features_1d import Features1DExperiment\n",
        "from signalAI.utils.group_dataset import GroupDataset\n",
        "from signalAI.utils.fold_idx_generator import (\n",
        "    FoldIdxGeneratorUnbiased,\n",
        "    FoldIdxGeneratorBiased,\n",
        ")\n",
        "\n",
        "class GroupCWRULoad(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        return sample[\"metainfo\"][\"load\"]\n",
        "\n",
        "class GroupCWRUSeverity(GroupDataset):\n",
        "    @staticmethod\n",
        "    def _assigne_group(sample: SignalSample) -> int:\n",
        "        severity = sample[\"metainfo\"][\"fault_size\"]\n",
        "\n",
        "        match severity:\n",
        "            case 0.0:\n",
        "                return sample[\"metainfo\"][\"load\"]\n",
        "            case 0.007:\n",
        "                return 0\n",
        "            case 0.014:\n",
        "                return 1\n",
        "            case 0.021:\n",
        "                return 2\n",
        "            case 0.028:\n",
        "                return 3\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gw9EnsSs276"
      },
      "source": [
        "# Deep Learning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRt2UWNpaPbh"
      },
      "source": [
        "## Import CRWU dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cckVlJSzUqnN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cached downloading...\n",
            "Hash: md5:d7d3042161080fc82e99d78464fa2914\n",
            "From (original): https://drive.google.com/uc?id=1G2vfms1QDlkdzqL_LAQdMIQAoludxBNj\n",
            "From (redirected): https://drive.google.com/uc?id=1G2vfms1QDlkdzqL_LAQdMIQAoludxBNj&confirm=t&uuid=341da9c5-55d9-4b58-90a0-ee7dfb779350\n",
            "To: ../data/raw_data/cwru/CWRU_raw/CWRU.zip\n",
            "100%|██████████| 245M/245M [00:02<00:00, 82.8MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "raw_root_dir = \"../data/raw_data/cwru\"\n",
        "raw_dataset = raw_datasets.CWRU_raw(raw_root_dir, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rDx-9rht7Un"
      },
      "source": [
        "## Time domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmIzuXr-aVBm"
      },
      "source": [
        "### 12k SampleRate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t09LPCnRtMbu",
        "outputId": "6aa32f9b-c9b5-4eb0-9507-1a6894c56c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(transforms=[SplitSampleRate(), Split(window_size=1024)])\n"
          ]
        }
      ],
      "source": [
        "transforms_time = Sequential(\n",
        "    [\n",
        "        SplitSampleRate(),\n",
        "        Split(1024)\n",
        "    ]\n",
        ")\n",
        "print(transforms_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NeeJ_8J3tRno"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformando\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting CWRU: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
          ]
        }
      ],
      "source": [
        "deep_root_dir_time = \"../data/deep_data/deep_learning\"\n",
        "deep_dataset_time = convertDataset(raw_dataset,filter=FilterByValue(on_field=\"sample_rate\", values=12000),transforms=transforms_time, dir_path=deep_root_dir_time, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gufU833iax3I"
      },
      "source": [
        "## Generate Unbiased Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd86Qz_Qth8u",
        "outputId": "74a72abc-7c83-4872-e1f3-7e698abb2344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grouping dataset: 100%|██████████| 27720/27720 [00:04<00:00, 6675.12sample/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 3., 3., 3.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folds_singleround_deep = FoldIdxGeneratorUnbiased(deep_dataset_time, GroupCWRULoad , dataset_name=\"CWRU12k_deep\").generate_folds()\n",
        "folds_singleround_deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Biased Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 2, 2, ..., 1, 0, 2])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folds_singleround_deep_biased = FoldIdxGeneratorBiased(deep_dataset_time, dataset_name=\"CWRU12k_deep\", n_folds=4).generate_folds()\n",
        "folds_singleround_deep_biased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1DdMvqe7Qs"
      },
      "source": [
        "## DeepLearning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt4WUe1EkNUQ"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sbq0v5_lgAAW"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/base.py\n",
        "from abc import ABC, abstractmethod\n",
        "import json\n",
        "from typing import Optional, Dict, Any\n",
        "from vibdata.raw.base import RawVibrationDataset\n",
        "from vibdata.deep.signal.transforms import Transform\n",
        "\n",
        "class Experiment(ABC):\n",
        "    \"\"\"Classe base abstrata para todos os experimentos de classificação de vibração.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset: Optional[RawVibrationDataset] = None,\n",
        "        data_transform: Optional[Transform] = None,\n",
        "        feature_selector = None,\n",
        "        model = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Inicializa o experimento.\n",
        "\n",
        "        Args:\n",
        "            name: Nome identificador do experimento\n",
        "            description: Descrição detalhada do experimento\n",
        "            dataset: Conjunto de dados de vibração\n",
        "            data_transform: Transformação a ser aplicada nos dados brutos\n",
        "            data_division_method: Método de divisão dos dados (e.g., 'kfold', 'holdout')\n",
        "            data_division_params: Parâmetros para o método de divisão\n",
        "            feature_selector: Seletor de features (para experimentos com extração)\n",
        "            model: Modelo de machine learning/deep learning\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.dataset = dataset\n",
        "        self.data_transform = data_transform\n",
        "        self.feature_selector = feature_selector\n",
        "        self.model = model\n",
        "\n",
        "        # Resultados serão armazenados aqui\n",
        "        self.results = {}\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepara os dados para o experimento.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self):\n",
        "        \"\"\"Executa o experimento completo.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def save_results(self, filepath: str):\n",
        "        \"\"\"Salva os resultados do experimento.\"\"\"\n",
        "        # Implementação básica - pode ser extendida\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(self.results, f)\n",
        "\n",
        "    def load_results(self, filepath: str):\n",
        "        \"\"\"Carrega resultados de um experimento anterior.\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            self.results = json.load(f)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Experiment: {self.name}\\nDescription: {self.description}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pS8nDnOpe_Le"
      },
      "outputs": [],
      "source": [
        "# vibclassifier/experiments/deep_torch.py\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Tuple, Union\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from signalAI.utils.metrics import calculate_metrics\n",
        "from signalAI.utils.experiment_result import ExperimentResults, FoldResults\n",
        "import copy\n",
        "\n",
        "class TorchVibrationDataset(Dataset):\n",
        "    \"\"\"Wrapper to convert dataset samples into Torch tensors.\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Função auxiliar KL\n",
        "def kl_divergence(rho, rho_hat):\n",
        "    rho_hat = torch.mean(rho_hat, dim=0)\n",
        "    rho = torch.tensor([rho] * len(rho_hat), device=rho_hat.device)\n",
        "    epsilon = 1e-7\n",
        "    term1 = rho * torch.log((rho + epsilon) / (rho_hat + epsilon))\n",
        "    term2 = (1 - rho) * torch.log((1 - rho + epsilon) / (1 - rho_hat + epsilon))\n",
        "    return torch.sum(term1 + term2)\n",
        "\n",
        "class DeepLearningExperiment(Experiment):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        dataset,\n",
        "        data_fold_idxs: List[int],\n",
        "        model: nn.Module,\n",
        "        criterion: Optional[nn.Module] = None,\n",
        "        # Parâmetros adaptados para o autoencoder\n",
        "        reconstruction_criterion: Optional[nn.Module] = None,\n",
        "        recon_loss_weight: float = 1.0,\n",
        "        sparsity_target: Optional[float] = None,\n",
        "        sparsity_weight: float = 0.0,\n",
        "        pretrain_epochs: int = 0, # Épocas de treinamento do autoencoder\n",
        "        optimizer_class: Optional[torch.optim.Optimizer] = optim.Adam,\n",
        "        batch_size: int = 32,\n",
        "        lr: float = 1e-3,\n",
        "        num_epochs: int = 20, # Épocas de treino do classificador\n",
        "        val_split: float = 0.2,\n",
        "        output_dir: str = \"results_torch\",\n",
        "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(name, description, dataset, model=model, **kwargs)\n",
        "        self.data_fold_idxs = data_fold_idxs\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.pretrain_epochs = pretrain_epochs\n",
        "        self.val_split = val_split\n",
        "        self.device = device\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.lr = lr\n",
        "        self.criterion = criterion if criterion is not None else nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.reconstruction_criterion = reconstruction_criterion\n",
        "        self.recon_loss_weight = recon_loss_weight\n",
        "        self.sparsity_target = sparsity_target\n",
        "        self.sparsity_weight = sparsity_weight\n",
        "        \n",
        "        self.is_sae_task = self.sparsity_target is not None and self.sparsity_weight > 0.0\n",
        "        # Define tipo do AutoEncoder utilizado\n",
        "        self.is_autoencoder_task = reconstruction_criterion is not None or self.is_sae_task or \"AE1D\" in model.__class__.__name__\n",
        "\n",
        "        if self.is_sae_task and self.reconstruction_criterion is None:\n",
        "             print(\"Warning: SAE task detected but no reconstruction_criterion. Defaulting to MSELoss.\")\n",
        "             self.reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
        "            model = torch.nn.DataParallel(model) \n",
        "        \n",
        "        # Guarda encoder e decoder\n",
        "        self.original_model = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        self.n_outer_folds = len(np.unique(data_fold_idxs))\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        features, labels = [], []\n",
        "        for sample in self.dataset:\n",
        "            features.append(sample['signal'][0]) \n",
        "            labels.append(sample['metainfo']['label'])\n",
        "        self.X = np.array(features)\n",
        "        self.y = np.array(labels)\n",
        "\n",
        "    def _train_one_fold(\n",
        "        self, X_train, y_train, X_test, y_test, fold_idx: int\n",
        "    ) -> FoldResults:\n",
        "        \n",
        "        train_dataset = TorchVibrationDataset(X_train, y_train)\n",
        "        test_dataset = TorchVibrationDataset(X_test, y_test)\n",
        "        val_size = int(self.val_split * len(train_dataset))\n",
        "        train_size = len(train_dataset) - val_size\n",
        "        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        model = copy.deepcopy(self.model.to(self.device))\n",
        "        model_core = model.module if isinstance(model, nn.DataParallel) else model\n",
        "\n",
        "        # Verificação da estrutura de AE (encoder, decoder, classifier)\n",
        "        has_ae_structure = hasattr(model_core, 'encoder') and hasattr(model_core, 'decoder') and hasattr(model_core, 'classifier')\n",
        "\n",
        "        # ============================================================\n",
        "        # TREINO DO AUTOENCODER\n",
        "        # ============================================================\n",
        "        if self.is_autoencoder_task and self.pretrain_epochs > 0 and has_ae_structure:\n",
        "            print(f\"[Fold {fold_idx}] AutoEncoder training ({self.pretrain_epochs} epochs)...\")\n",
        "            \n",
        "            # Otimizador Encoder + Decoder\n",
        "            optimizer_ae = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.decoder.parameters()}\n",
        "            ], lr=self.lr)\n",
        "\n",
        "            for epoch in range(self.pretrain_epochs):\n",
        "                model.train()\n",
        "                running_recon_loss = 0.0\n",
        "                \n",
        "                for xb, _ in train_loader:\n",
        "                    xb = xb.to(self.device)\n",
        "                    input_data = xb\n",
        "\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                        xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    optimizer_ae.zero_grad()\n",
        "                    outputs = model(xb) # (class, recon, [sparsity])\n",
        "\n",
        "                    if isinstance(outputs, tuple):\n",
        "                        # Foco na reconstrução\n",
        "                        reconstruction = outputs[1] \n",
        "                        \n",
        "                        loss = self.reconstruction_criterion(reconstruction, input_data)\n",
        "                        \n",
        "                        # Adiciona esparsidade se for SAE\n",
        "                        if self.is_sae_task and len(outputs) > 2:\n",
        "                            latent_features = outputs[2]\n",
        "                            loss += self.sparsity_weight * kl_divergence(self.sparsity_target, latent_features)\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer_ae.step()\n",
        "                        running_recon_loss += loss.item() * input_data.size(0)\n",
        "                \n",
        "                avg_recon_loss = running_recon_loss / len(train_loader.dataset)\n",
        "                if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                    print(f\"  [Pre-train] Epoch {epoch+1}/{self.pretrain_epochs} Recon Loss: {avg_recon_loss:.4f}\")\n",
        "\n",
        "        # ============================================================\n",
        "        # TREINO DO CLASSIFICADOR\n",
        "        # ============================================================\n",
        "        print(f\"[Fold {fold_idx}] Classifier training ({self.num_epochs} epochs)...\")\n",
        "\n",
        "        # Define otimizador para a fase supervisionada\n",
        "        if has_ae_structure and self.is_autoencoder_task:\n",
        "            # Se for AE: Treina Encoder + Classifier (Decoder congelado ou ignorado pelo otimizador)\n",
        "            optimizer_clf = self.optimizer_class([\n",
        "                {'params': model_core.encoder.parameters()},\n",
        "                {'params': model_core.classifier.parameters()}\n",
        "            ], lr=self.lr)\n",
        "        else:\n",
        "            # Se for MLP/CNN padrão: Treina todos os parâmetros\n",
        "            optimizer_clf = self.optimizer_class(model.parameters(), lr=self.lr)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "        \n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_start = time.time()\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            for xb, yb in train_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                \n",
        "                # Ajuste de shape\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                optimizer_clf.zero_grad()\n",
        "                outputs = model(xb)\n",
        "\n",
        "                # Cálculo da perda apenas de CLASSIFICAÇÃO\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0] # Pega apenas a classificação\n",
        "                else:\n",
        "                    classification_output = outputs # Modelo padrão\n",
        "\n",
        "                loss = self.criterion(classification_output, yb)\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer_clf.step()\n",
        "                running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "            # Validação\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                    # Ajuste de shape\n",
        "                    if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         xb = xb.unsqueeze(1)\n",
        "                    elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                         side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                    outputs = model(xb)\n",
        "                    \n",
        "                    if isinstance(outputs, tuple):\n",
        "                        classification_output = outputs[0]\n",
        "                    else:\n",
        "                        classification_output = outputs\n",
        "\n",
        "                    loss = self.criterion(classification_output, yb)\n",
        "                    val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "            \n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(avg_val_loss)\n",
        "            \n",
        "            epoch_time = time.time() - epoch_start\n",
        "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "                print(f\"  [Supervised] Epoch {epoch+1}/{self.num_epochs} Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(train_losses, label=\"Train Loss (Clf)\")\n",
        "        plt.plot(val_losses, label=\"Val Loss (Clf)\")\n",
        "        plt.legend(); plt.title(f\"Loss Curve - Fold {fold_idx}\")\n",
        "        plt.savefig(os.path.join(self.dir_path, f\"loss_curve_fold{fold_idx}_{self.start_time}.png\")); plt.close()\n",
        "        \n",
        "        torch.save(model_core.state_dict(), os.path.join(self.dir_path, f\"model_fold{fold_idx}.pt\"))\n",
        "\n",
        "        # Teste\n",
        "        y_true, y_pred, y_proba = [], [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                if any(isinstance(m, nn.Conv1d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     xb = xb.unsqueeze(1)\n",
        "                elif any(isinstance(m, nn.Conv2d) for m in model.modules()) and xb.ndim == 2:\n",
        "                     side = int(np.sqrt(xb.shape[1])); xb = xb.view(xb.size(0), 1, side, side)\n",
        "\n",
        "                outputs = model(xb)\n",
        "                if isinstance(outputs, tuple):\n",
        "                    classification_output = outputs[0]\n",
        "                else:\n",
        "                    classification_output = outputs\n",
        "\n",
        "                probs = torch.softmax(classification_output, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                y_true.extend(yb.cpu().numpy()); y_pred.extend(preds.cpu().numpy()); y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "        metrics = calculate_metrics(np.array(y_true), np.array(y_pred), np.array(y_proba))\n",
        "        return FoldResults(fold_idx, np.array(y_true), np.array(y_pred), np.array(y_proba), metrics)\n",
        "\n",
        "    def run(self) -> ExperimentResults:\n",
        "        self.start_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.dir_path = os.path.join(self.output_dir, f\"results_{self.name}_{self.start_time}\")\n",
        "        os.makedirs(self.dir_path, exist_ok=True)\n",
        "\n",
        "        results = ExperimentResults(\n",
        "            experiment_name=self.name, description=self.description,\n",
        "            model_name=self.original_model.__class__.__name__, feature_names=None,\n",
        "            config={'n_outer_folds': self.n_outer_folds, 'pretrain_epochs': self.pretrain_epochs, \n",
        "                    'finetune_epochs': self.num_epochs, 'batch_size': self.batch_size, 'lr': self.lr}\n",
        "        )\n",
        "\n",
        "        for outer_fold in range(self.n_outer_folds):\n",
        "            print(f\"\\n=== Outer Fold {outer_fold+1}/{self.n_outer_folds} ===\")\n",
        "            train_mask = self.data_fold_idxs != outer_fold\n",
        "            test_mask = self.data_fold_idxs == outer_fold\n",
        "            \n",
        "            try:\n",
        "                fold_result = self._train_one_fold(self.X[train_mask], self.y[train_mask], self.X[test_mask], self.y[test_mask], outer_fold)\n",
        "                results.add_fold_result(fold_result)\n",
        "                print(f\"  Result: Acc={fold_result.metrics['accuracy']:.4f}, F1={fold_result.metrics['f1']:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in fold {outer_fold}: {e}\")\n",
        "                import traceback; traceback.print_exc()\n",
        "\n",
        "        results.calculate_overall_metrics()\n",
        "        results.save_json(os.path.join(self.dir_path, f\"results.json\"))\n",
        "        print(\"\\n=== Final Results ===\")\n",
        "        print(f\"Mean Accuracy: {results.overall_metrics['accuracy']:.4f}\")\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PboZEAgOtN2R"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do MLP 1D conforme benchmark (Zhao et al., 2020).\n",
        "    Arquitetura: 1024 -> 512 -> 256 -> 128 -> 64 -> num_classes\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, num_classes: int = 4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(input_length, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc5 = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc6 = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc7 = nn.Sequential(\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Achata o input para (Batch_Size, Features) permitindo entradas (N, 1, 1024) ou (N, 1024)\n",
        "        out = torch.flatten(x, 1)\n",
        "                \n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.fc5(out)\n",
        "        out = self.fc6(out)\n",
        "        out = self.fc7(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFOzfg7Atozy",
        "outputId": "78ab4e89-dbdc-4024-d25d-50d2db5745a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 1024, Num classes: 4\n",
            "\n",
            "=== Outer Fold 1/4 ===\n",
            "[Fold 0] Classifier training (100 epochs)...\n",
            "  [Supervised] Epoch 1/100 Train Loss: 0.9000, Val Loss: 0.7154, Time: 7.78s\n",
            "  [Supervised] Epoch 5/100 Train Loss: 0.1883, Val Loss: 0.5380, Time: 7.02s\n",
            "  [Supervised] Epoch 10/100 Train Loss: 0.1104, Val Loss: 0.6780, Time: 6.92s\n",
            "  [Supervised] Epoch 15/100 Train Loss: 0.0800, Val Loss: 0.6976, Time: 7.24s\n",
            "  [Supervised] Epoch 20/100 Train Loss: 0.0590, Val Loss: 0.6264, Time: 7.53s\n",
            "  [Supervised] Epoch 25/100 Train Loss: 0.0499, Val Loss: 0.6673, Time: 7.79s\n",
            "  [Supervised] Epoch 30/100 Train Loss: 0.0452, Val Loss: 0.8382, Time: 8.51s\n",
            "  [Supervised] Epoch 35/100 Train Loss: 0.0436, Val Loss: 0.5928, Time: 7.30s\n",
            "  [Supervised] Epoch 40/100 Train Loss: 0.0362, Val Loss: 0.6686, Time: 7.66s\n",
            "  [Supervised] Epoch 45/100 Train Loss: 0.0393, Val Loss: 0.6035, Time: 7.71s\n",
            "  [Supervised] Epoch 50/100 Train Loss: 0.0232, Val Loss: 0.7527, Time: 7.70s\n",
            "  [Supervised] Epoch 55/100 Train Loss: 0.0256, Val Loss: 0.7694, Time: 7.62s\n",
            "  [Supervised] Epoch 60/100 Train Loss: 0.0268, Val Loss: 0.6324, Time: 7.66s\n",
            "  [Supervised] Epoch 65/100 Train Loss: 0.0230, Val Loss: 0.6754, Time: 7.71s\n",
            "  [Supervised] Epoch 70/100 Train Loss: 0.0209, Val Loss: 0.5315, Time: 7.43s\n",
            "  [Supervised] Epoch 75/100 Train Loss: 0.0239, Val Loss: 0.6588, Time: 7.05s\n",
            "  [Supervised] Epoch 80/100 Train Loss: 0.0188, Val Loss: 0.7616, Time: 6.94s\n",
            "  [Supervised] Epoch 85/100 Train Loss: 0.0159, Val Loss: 0.6577, Time: 6.94s\n",
            "  [Supervised] Epoch 90/100 Train Loss: 0.0178, Val Loss: 0.6192, Time: 6.98s\n",
            "  [Supervised] Epoch 95/100 Train Loss: 0.0159, Val Loss: 0.8000, Time: 6.94s\n",
            "  [Supervised] Epoch 100/100 Train Loss: 0.0130, Val Loss: 0.8625, Time: 7.15s\n",
            "  Result: Acc=0.5259, F1=0.5274\n",
            "\n",
            "=== Outer Fold 2/4 ===\n",
            "[Fold 1] Classifier training (100 epochs)...\n",
            "  [Supervised] Epoch 1/100 Train Loss: 0.9281, Val Loss: 0.7858, Time: 7.48s\n",
            "  [Supervised] Epoch 5/100 Train Loss: 0.2650, Val Loss: 0.6092, Time: 7.24s\n",
            "  [Supervised] Epoch 10/100 Train Loss: 0.1400, Val Loss: 0.7193, Time: 7.44s\n",
            "  [Supervised] Epoch 15/100 Train Loss: 0.1019, Val Loss: 0.7736, Time: 7.53s\n",
            "  [Supervised] Epoch 20/100 Train Loss: 0.0850, Val Loss: 0.7345, Time: 7.45s\n",
            "  [Supervised] Epoch 25/100 Train Loss: 0.0720, Val Loss: 0.7105, Time: 6.94s\n",
            "  [Supervised] Epoch 30/100 Train Loss: 0.0567, Val Loss: 0.8652, Time: 6.68s\n",
            "  [Supervised] Epoch 35/100 Train Loss: 0.0569, Val Loss: 0.7810, Time: 6.74s\n",
            "  [Supervised] Epoch 40/100 Train Loss: 0.0482, Val Loss: 0.8370, Time: 7.39s\n",
            "  [Supervised] Epoch 45/100 Train Loss: 0.0442, Val Loss: 0.8385, Time: 7.47s\n",
            "  [Supervised] Epoch 50/100 Train Loss: 0.0365, Val Loss: 0.8306, Time: 7.53s\n",
            "  [Supervised] Epoch 55/100 Train Loss: 0.0364, Val Loss: 0.8338, Time: 7.43s\n",
            "  [Supervised] Epoch 60/100 Train Loss: 0.0367, Val Loss: 0.9353, Time: 6.73s\n",
            "  [Supervised] Epoch 65/100 Train Loss: 0.0304, Val Loss: 1.1408, Time: 6.85s\n",
            "  [Supervised] Epoch 70/100 Train Loss: 0.0321, Val Loss: 0.9365, Time: 6.88s\n",
            "  [Supervised] Epoch 75/100 Train Loss: 0.0263, Val Loss: 1.1126, Time: 7.88s\n",
            "  [Supervised] Epoch 80/100 Train Loss: 0.0249, Val Loss: 0.7994, Time: 7.12s\n",
            "  [Supervised] Epoch 85/100 Train Loss: 0.0219, Val Loss: 0.9222, Time: 7.56s\n",
            "  [Supervised] Epoch 90/100 Train Loss: 0.0259, Val Loss: 0.8091, Time: 7.55s\n",
            "  [Supervised] Epoch 95/100 Train Loss: 0.0206, Val Loss: 0.8407, Time: 7.52s\n",
            "  [Supervised] Epoch 100/100 Train Loss: 0.0222, Val Loss: 0.9888, Time: 7.59s\n",
            "  Result: Acc=0.6612, F1=0.6576\n",
            "\n",
            "=== Outer Fold 3/4 ===\n",
            "[Fold 2] Classifier training (100 epochs)...\n",
            "  [Supervised] Epoch 1/100 Train Loss: 0.9377, Val Loss: 0.7840, Time: 6.78s\n",
            "  [Supervised] Epoch 5/100 Train Loss: 0.2741, Val Loss: 0.5524, Time: 7.46s\n",
            "  [Supervised] Epoch 10/100 Train Loss: 0.1473, Val Loss: 0.5922, Time: 6.80s\n",
            "  [Supervised] Epoch 15/100 Train Loss: 0.1022, Val Loss: 0.5631, Time: 6.82s\n",
            "  [Supervised] Epoch 20/100 Train Loss: 0.0887, Val Loss: 0.7709, Time: 6.79s\n",
            "  [Supervised] Epoch 25/100 Train Loss: 0.0718, Val Loss: 0.7198, Time: 7.04s\n",
            "  [Supervised] Epoch 30/100 Train Loss: 0.0606, Val Loss: 0.6877, Time: 7.57s\n",
            "  [Supervised] Epoch 35/100 Train Loss: 0.0554, Val Loss: 0.6743, Time: 7.56s\n",
            "  [Supervised] Epoch 40/100 Train Loss: 0.0589, Val Loss: 0.7111, Time: 7.47s\n",
            "  [Supervised] Epoch 45/100 Train Loss: 0.0488, Val Loss: 0.7302, Time: 7.56s\n",
            "  [Supervised] Epoch 50/100 Train Loss: 0.0394, Val Loss: 0.7812, Time: 6.83s\n",
            "  [Supervised] Epoch 55/100 Train Loss: 0.0333, Val Loss: 0.8874, Time: 6.74s\n",
            "  [Supervised] Epoch 60/100 Train Loss: 0.0306, Val Loss: 0.8869, Time: 6.81s\n",
            "  [Supervised] Epoch 65/100 Train Loss: 0.0287, Val Loss: 0.7154, Time: 7.26s\n",
            "  [Supervised] Epoch 70/100 Train Loss: 0.0293, Val Loss: 0.8166, Time: 7.49s\n",
            "  [Supervised] Epoch 75/100 Train Loss: 0.0253, Val Loss: 0.7097, Time: 7.64s\n",
            "  [Supervised] Epoch 80/100 Train Loss: 0.0324, Val Loss: 0.8449, Time: 7.71s\n",
            "  [Supervised] Epoch 85/100 Train Loss: 0.0233, Val Loss: 0.6596, Time: 7.49s\n",
            "  [Supervised] Epoch 90/100 Train Loss: 0.0219, Val Loss: 0.8176, Time: 7.24s\n",
            "  [Supervised] Epoch 95/100 Train Loss: 0.0226, Val Loss: 0.8603, Time: 6.77s\n",
            "  [Supervised] Epoch 100/100 Train Loss: 0.0165, Val Loss: 0.7048, Time: 7.09s\n",
            "  Result: Acc=0.7016, F1=0.6971\n",
            "\n",
            "=== Outer Fold 4/4 ===\n",
            "[Fold 3] Classifier training (100 epochs)...\n",
            "  [Supervised] Epoch 1/100 Train Loss: 0.9270, Val Loss: 0.7763, Time: 7.72s\n",
            "  [Supervised] Epoch 5/100 Train Loss: 0.2495, Val Loss: 0.6310, Time: 6.82s\n",
            "  [Supervised] Epoch 10/100 Train Loss: 0.1390, Val Loss: 0.6470, Time: 7.03s\n",
            "  [Supervised] Epoch 15/100 Train Loss: 0.0965, Val Loss: 0.9584, Time: 7.03s\n",
            "  [Supervised] Epoch 20/100 Train Loss: 0.0744, Val Loss: 0.7365, Time: 7.46s\n",
            "  [Supervised] Epoch 25/100 Train Loss: 0.0671, Val Loss: 0.7716, Time: 7.62s\n",
            "  [Supervised] Epoch 30/100 Train Loss: 0.0563, Val Loss: 0.9058, Time: 7.64s\n",
            "  [Supervised] Epoch 35/100 Train Loss: 0.0475, Val Loss: 0.7010, Time: 7.54s\n",
            "  [Supervised] Epoch 40/100 Train Loss: 0.0490, Val Loss: 0.6987, Time: 7.63s\n",
            "  [Supervised] Epoch 45/100 Train Loss: 0.0421, Val Loss: 0.6830, Time: 7.67s\n",
            "  [Supervised] Epoch 50/100 Train Loss: 0.0364, Val Loss: 0.8167, Time: 7.49s\n",
            "  [Supervised] Epoch 55/100 Train Loss: 0.0369, Val Loss: 0.7892, Time: 6.89s\n",
            "  [Supervised] Epoch 60/100 Train Loss: 0.0331, Val Loss: 0.9223, Time: 6.91s\n",
            "  [Supervised] Epoch 65/100 Train Loss: 0.0283, Val Loss: 0.8846, Time: 6.77s\n",
            "  [Supervised] Epoch 70/100 Train Loss: 0.0255, Val Loss: 0.9599, Time: 6.95s\n",
            "  [Supervised] Epoch 75/100 Train Loss: 0.0206, Val Loss: 0.7920, Time: 7.23s\n",
            "  [Supervised] Epoch 80/100 Train Loss: 0.0210, Val Loss: 0.7402, Time: 7.53s\n",
            "  [Supervised] Epoch 85/100 Train Loss: 0.0324, Val Loss: 0.8103, Time: 7.44s\n",
            "  [Supervised] Epoch 90/100 Train Loss: 0.0197, Val Loss: 1.0233, Time: 7.47s\n",
            "  [Supervised] Epoch 95/100 Train Loss: 0.0177, Val Loss: 0.8280, Time: 7.49s\n",
            "  [Supervised] Epoch 100/100 Train Loss: 0.0163, Val Loss: 0.6699, Time: 7.37s\n",
            "  Result: Acc=0.7229, F1=0.7176\n",
            "\n",
            "=== Final Results ===\n",
            "Mean Accuracy: 0.6529\n"
          ]
        }
      ],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = MLP1D(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"mlp1d_vibration\",\n",
        "    description=\"1D MLP for vibration signals\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,  # numpy array of fold indexes\n",
        "    model=model,\n",
        "    batch_size=64,\n",
        "    lr=1e-3,\n",
        "    pretrain_epochs=0,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEE_ePYwV08q"
      },
      "source": [
        "### 1D AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yLqcRhHgWLqV"
      },
      "outputs": [],
      "source": [
        "class AE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Autoencoder 1D conforme benchmark (Zhao et al., 2020).\n",
        "    Arquitetura: 1024 -> 512 -> 256 -> 128 -> 64 (Latent) -> 128 -> 256 -> 512 -> 1024.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, latent_dim: int = 64, num_classes: int = 4, dropout_rate: float = 0.4):\n",
        "        super(AE1D, self).__init__()\n",
        "        \n",
        "        # --- Encoder ---\n",
        "        # Reduz a dimensão progressivamente para extrair features\n",
        "        # O uso de Dropout aqui cria um \"Denoising effect\" implícito nas features latentes\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Camada 1: 1024 -> 512 (Redução imediata conforme padrão do artigo)\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada 2: 512 -> 256\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada 3: 256 -> 128\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Camada Latente: 128 -> 64\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # Espelha o encoder para reconstrução. \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Camada final de reconstrução\n",
        "            nn.Linear(512, input_length) # Sem ativação final (Linear) devido dados padronizados (StandardScaler)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Garante (Batch, Features)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        # Encoder\n",
        "        latent_features = self.encoder(x)\n",
        "        \n",
        "        # Decoder (Reconstrução)\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "        \n",
        "        # Classifier (Diagnóstico)\n",
        "        classification_output = self.classifier(latent_features)\n",
        "        \n",
        "        return classification_output, reconstruction, latent_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "67yzEiLJXKKE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 1024, Num classes: 4\n",
            "\n",
            "=== Outer Fold 1/4 ===\n",
            "[Fold 0] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1308\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1184\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1163\n",
            "[Fold 0] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.1428, Val Loss: 0.9492, Time: 4.89s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.6120, Val Loss: 0.6089, Time: 4.46s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.3493, Val Loss: 0.5042, Time: 4.49s\n",
            "  Result: Acc=0.5215, F1=0.5081\n",
            "\n",
            "=== Outer Fold 2/4 ===\n",
            "[Fold 1] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1421\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1268\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1239\n",
            "[Fold 1] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.1332, Val Loss: 0.9651, Time: 4.50s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.6621, Val Loss: 0.6743, Time: 4.45s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.4583, Val Loss: 0.6036, Time: 4.34s\n",
            "  Result: Acc=0.6239, F1=0.6163\n",
            "\n",
            "=== Outer Fold 3/4 ===\n",
            "[Fold 2] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1385\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1236\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1201\n",
            "[Fold 2] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.1127, Val Loss: 0.9434, Time: 4.47s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.6597, Val Loss: 0.6745, Time: 4.77s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.4480, Val Loss: 0.5836, Time: 4.33s\n",
            "  Result: Acc=0.6406, F1=0.6385\n",
            "\n",
            "=== Outer Fold 4/4 ===\n",
            "[Fold 3] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1377\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1229\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1204\n",
            "[Fold 3] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.0999, Val Loss: 0.9790, Time: 4.62s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.6421, Val Loss: 0.6887, Time: 4.35s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.4271, Val Loss: 0.5594, Time: 4.33s\n",
            "  Result: Acc=0.6726, F1=0.6695\n",
            "\n",
            "=== Final Results ===\n",
            "Mean Accuracy: 0.6146\n"
          ]
        }
      ],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = AE1D(input_length=input_length, latent_dim=64, num_classes=num_classes)\n",
        "\n",
        "# Defina os critérios\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"ae1d_vibration_combined_loss\",\n",
        "    description=\"1D AE for vibration signals (Combined Loss)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # critério para treinamento do autoencoder\n",
        "    criterion=classification_criterion,                # critério para treinamento do classificador\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder apenas com MSELoss\n",
        "    num_epochs=10,       # Treina Encoder+Classifier apenas com CrossEntropy\n",
        "    recon_loss_weight=1.0, # recon_loss_weight pode ser 1.0 (pois é a única loss na fase 1)\n",
        "    batch_size=64,\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOiLccpyM4U0"
      },
      "source": [
        "### 1D Sparse AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rnpj0Q8oM-1r"
      },
      "outputs": [],
      "source": [
        "class SAE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Sparse Autoencoder 1D (Zhao et al., 2020).\n",
        "    Arquitetura: 1024 -> 512 -> 256 -> 128 -> 64 (Latent).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, latent_dim: int = 64, num_classes: int = 4):\n",
        "        super(SAE1D, self).__init__()\n",
        "        \n",
        "        # --- Encoder ---\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Ativação específica para impor restrição (0,1) para a penalidade de esparsidade (KL Divergence)\n",
        "        self.sparsity_activation = nn.Sigmoid()\n",
        "\n",
        "        # --- Decoder ---\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(512, input_length)\n",
        "        )\n",
        "\n",
        "        # Classificador para a fase de Fine-Tuning\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Garante achatamento (Batch, 1024)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # 1. Codificação\n",
        "        features = self.encoder(x)\n",
        "        \n",
        "        # 2. Aplicação da não-linearidade para Esparsidade (Latent Space)\n",
        "        latent_features = self.sparsity_activation(features)\n",
        "\n",
        "        # 3. Decodificação (Reconstrução) baseada nas features esparsas\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "\n",
        "        # 4. Classificação (Diagnóstico)\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        return classification_output, reconstruction, latent_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 1024, Num classes: 4\n",
            "\n",
            "=== Outer Fold 1/4 ===\n",
            "[Fold 0] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 2.3288\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1229\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1156\n",
            "[Fold 0] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.0765, Val Loss: 0.8768, Time: 4.74s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2076, Val Loss: 0.5060, Time: 3.92s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.0992, Val Loss: 0.5595, Time: 4.78s\n",
            "  Result: Acc=0.5212, F1=0.5164\n",
            "\n",
            "=== Outer Fold 2/4 ===\n",
            "[Fold 1] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 2.3976\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1331\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1253\n",
            "[Fold 1] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.0840, Val Loss: 0.8885, Time: 3.98s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2736, Val Loss: 0.6478, Time: 3.93s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.1415, Val Loss: 0.6391, Time: 3.96s\n",
            "  Result: Acc=0.6849, F1=0.6761\n",
            "\n",
            "=== Outer Fold 3/4 ===\n",
            "[Fold 2] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 2.4191\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1222\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1163\n",
            "[Fold 2] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.0972, Val Loss: 0.9219, Time: 4.37s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2680, Val Loss: 0.6359, Time: 4.19s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.1388, Val Loss: 0.6481, Time: 4.74s\n",
            "  Result: Acc=0.6659, F1=0.6574\n",
            "\n",
            "=== Outer Fold 4/4 ===\n",
            "[Fold 3] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 2.3906\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1263\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1200\n",
            "[Fold 3] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.1024, Val Loss: 0.9039, Time: 3.97s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2524, Val Loss: 0.6035, Time: 3.98s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.1248, Val Loss: 0.5872, Time: 4.02s\n",
            "  Result: Acc=0.6953, F1=0.6898\n",
            "\n",
            "=== Final Results ===\n",
            "Mean Accuracy: 0.6418\n"
          ]
        }
      ],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "model = SAE1D(input_length=input_length, latent_dim=64, num_classes=num_classes)\n",
        "\n",
        "# loss criterions\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"sae1d_vibration_sequential\",\n",
        "    description=\"1D Sparse AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder com MSE + Esparsidade KL\n",
        "    num_epochs=10,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    sparsity_target=0.05,  # (Rho) Nível de esparsidade desejado (ex: 5% dos neurônios ativos) \n",
        "    sparsity_weight=1.0,   # (Beta) Peso da penalidade KL na perda total\n",
        "    recon_loss_weight=1.0, # Peso da reconstrução (geralmente 1.0 na fase de pré-treino puro)\n",
        "    batch_size=64,\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D Denoising AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DAE1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação do Denoising Autoencoder (DAE) 1D.\n",
        "    Segue a arquitetura de referência do benchmark CWRU (Zhao et al., 2020).\n",
        "    Arquitetura: 1024 -> 512 -> 256 -> 128 -> 64 (Latent).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, latent_dim: int = 64, num_classes: int = 4, noise_factor: float = 0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            noise_factor: Desvio padrão do ruído Gaussiano adicionado (sigma).\n",
        "        \"\"\"\n",
        "        super(DAE1D, self).__init__()\n",
        "        self.noise_factor = noise_factor\n",
        "        \n",
        "        # --- Encoder ---\n",
        "        # 1024 -> 512 -> 256 -> 128 -> 64\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_length, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # 64 -> 128 -> 256 -> 512 -> 1024\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(512, input_length)\n",
        "        )\n",
        "\n",
        "        # --- Classificador (Fine-tuning) ---\n",
        "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Garante (Batch, 1024)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # --- Passo de Denoising (Apenas no Treino) ---\n",
        "        if self.training:\n",
        "            # Ruído Gaussiano (Normal): Média 0, Desvio Padrão = noise_factor\n",
        "            # O artigo geralmente usa ruído aditivo.\n",
        "            noise = torch.randn_like(x) * self.noise_factor\n",
        "            x_noisy = x + noise\n",
        "        else:\n",
        "            x_noisy = x\n",
        "        \n",
        "        # 1. Encode (recebe entrada ruidosa)\n",
        "        latent_features = self.encoder(x_noisy)\n",
        "        \n",
        "        # 2. Decode (tenta reconstruir)\n",
        "        reconstruction = self.decoder(latent_features)\n",
        "        \n",
        "        # 3. Classify (diagnóstico)\n",
        "        classification_output = self.classifier(latent_features)\n",
        "\n",
        "        # Retorna x_noisy opcionalmente para visualização se necessário, \n",
        "        # mas para o treino precisamos: class, recon\n",
        "        return classification_output, reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 1024, Num classes: 4\n",
            "\n",
            "=== Outer Fold 1/4 ===\n",
            "[Fold 0] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1272\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1128\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1070\n",
            "[Fold 0] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.2620, Val Loss: 1.2533, Time: 4.16s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 1.1416, Val Loss: 1.3213, Time: 4.92s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 1.0873, Val Loss: 1.3111, Time: 4.29s\n",
            "  Result: Acc=0.2688, F1=0.2734\n",
            "\n",
            "=== Outer Fold 2/4 ===\n",
            "[Fold 1] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1401\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1237\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1184\n",
            "[Fold 1] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.2601, Val Loss: 1.2528, Time: 4.81s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 1.1231, Val Loss: 1.3713, Time: 4.00s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 1.0726, Val Loss: 1.3226, Time: 4.51s\n",
            "  Result: Acc=0.2604, F1=0.2400\n",
            "\n",
            "=== Outer Fold 3/4 ===\n",
            "[Fold 2] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1385\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1228\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1174\n",
            "[Fold 2] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.2650, Val Loss: 1.2461, Time: 4.08s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 1.1465, Val Loss: 1.3063, Time: 4.67s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 1.0961, Val Loss: 1.3667, Time: 4.02s\n",
            "  Result: Acc=0.3351, F1=0.3335\n",
            "\n",
            "=== Outer Fold 4/4 ===\n",
            "[Fold 3] AutoEncoder training (10 epochs)...\n",
            "  [Pre-train] Epoch 1/10 Recon Loss: 0.1352\n",
            "  [Pre-train] Epoch 5/10 Recon Loss: 0.1226\n",
            "  [Pre-train] Epoch 10/10 Recon Loss: 0.1183\n",
            "[Fold 3] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 1.2706, Val Loss: 1.2771, Time: 4.59s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 1.1577, Val Loss: 1.1623, Time: 4.06s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 1.0942, Val Loss: 1.3900, Time: 4.77s\n",
            "  Result: Acc=0.4409, F1=0.4154\n",
            "\n",
            "=== Final Results ===\n",
            "Mean Accuracy: 0.3263\n"
          ]
        }
      ],
      "source": [
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "\n",
        "# noise_factor controla o ruído\n",
        "model = DAE1D(input_length=input_length, latent_dim=64, num_classes=num_classes, noise_factor=0.5)\n",
        "\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "# 4. Configuração do Experimento\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"dae1d_vibration_sequential\",\n",
        "    description=\"1D Denoising AE for vibration signals (Sequential Training)\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    reconstruction_criterion=reconstruction_criterion, # ae train\n",
        "    criterion=classification_criterion,                # classifier train\n",
        "    pretrain_epochs=10,  # Treina Encoder+Decoder com MSELoss (DAE)\n",
        "    num_epochs=10,       # Treina Encoder+Classifier com CrossEntropy\n",
        "    recon_loss_weight=1.0,\n",
        "    batch_size=64, # Batch grande ajuda na estabilidade do AE\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "# 5. Execução\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gH40Mtt9RyYs"
      },
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementação da 1D CNN baseada no Benchmark (Zhao et al., 2020).\n",
        "    Arquitetura: 4 Camadas de Convolução + 3 Camadas Densas.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int = 1024, num_classes: int = 10):\n",
        "        super(CNN1D, self).__init__()\n",
        "        \n",
        "        # Bloco de Extração de Features 1\n",
        "        # Convoluções iniciais para capturar padrões brutos\n",
        "        self.features1 = nn.Sequential(\n",
        "            # Camada 1: Kernel médio (15) para capturar tendências locais\n",
        "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=15, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Camada 2: Kernel fino (3) para refinar features\n",
        "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Pooling agressivo para redução de dimensão\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        # Bloco de Extração de Features 2        \n",
        "        self.features2 = nn.Sequential(\n",
        "            # Camada 3: Aumenta canais para 64\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Camada 4: Aumenta canais para 128\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # Adaptive Pool garante que a saída seja sempre (Batch, 128, 4)\n",
        "            # Isso independente de pequenas variações no input_length\n",
        "            nn.AdaptiveMaxPool1d(output_size=4)\n",
        "        )\n",
        "        \n",
        "        # Classificador (MLP Head)\n",
        "        # Input: 128 canais * 4 pontos = 512 features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            \n",
        "            # FC 1\n",
        "            nn.Linear(128 * 4, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5), # para evitar overfitting\n",
        "            \n",
        "            # FC 2\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            # Output\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Tratamento de Dimensão: Garante (Batch, 1, Length)\n",
        "        # Se vier (Batch, Length), adiciona a dimensão de canal\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        # 2. Extração de Features\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        \n",
        "        # 3. Classificação\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 1024, Num classes: 4\n",
            "\n",
            "=== Outer Fold 1/4 ===\n",
            "[Fold 0] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 0.8494, Val Loss: 0.3777, Time: 92.20s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.1503, Val Loss: 0.0598, Time: 85.62s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.0757, Val Loss: 0.0454, Time: 86.22s\n",
            "  Result: Acc=0.7629, F1=0.7618\n",
            "\n",
            "=== Outer Fold 2/4 ===\n",
            "[Fold 1] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 0.8892, Val Loss: 0.5223, Time: 77.86s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2129, Val Loss: 0.1327, Time: 81.84s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.1147, Val Loss: 0.0513, Time: 81.80s\n",
            "  Result: Acc=0.9571, F1=0.9570\n",
            "\n",
            "=== Outer Fold 3/4 ===\n",
            "[Fold 2] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 0.8853, Val Loss: 0.5622, Time: 82.55s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.2136, Val Loss: 0.1309, Time: 82.42s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.1263, Val Loss: 0.0862, Time: 82.58s\n",
            "  Result: Acc=0.9821, F1=0.9820\n",
            "\n",
            "=== Outer Fold 4/4 ===\n",
            "[Fold 3] Classifier training (10 epochs)...\n",
            "  [Supervised] Epoch 1/10 Train Loss: 0.8593, Val Loss: 0.4384, Time: 81.74s\n",
            "  [Supervised] Epoch 5/10 Train Loss: 0.1904, Val Loss: 0.1302, Time: 83.18s\n",
            "  [Supervised] Epoch 10/10 Train Loss: 0.0769, Val Loss: 0.0465, Time: 82.98s\n",
            "  Result: Acc=0.8746, F1=0.8724\n",
            "\n",
            "=== Final Results ===\n",
            "Mean Accuracy: 0.8942\n"
          ]
        }
      ],
      "source": [
        "# suppose dataset is already a DeepDataset like before\n",
        "input_length = deep_dataset_time[0]['signal'][0].shape[-1]\n",
        "num_classes = len(set([s['metainfo']['label'] for s in deep_dataset_time]))\n",
        "\n",
        "print(f\"Input length: {input_length}, Num classes: {num_classes}\")\n",
        "model = CNN1D(input_length=input_length, num_classes=num_classes)\n",
        "\n",
        "exp = DeepLearningExperiment(\n",
        "    name=\"cnn1d_7layers_vibration\",\n",
        "    description=\"1D CNN with 7 layers\",\n",
        "    dataset=deep_dataset_time,\n",
        "    data_fold_idxs=folds_singleround_deep,\n",
        "    model=model,\n",
        "    batch_size=64, \n",
        "    lr=1e-3,       \n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "results = exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PPXmkt-iKCeA",
        "Bt4WUe1EkNUQ",
        "pEE_ePYwV08q",
        "9RzAtB1FtI1t",
        "5y2zAwCJuAkM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
